{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:08.018637Z",
     "iopub.status.busy": "2021-06-16T15:23:08.018060Z",
     "iopub.status.idle": "2021-06-16T15:23:09.387014Z",
     "shell.execute_reply": "2021-06-16T15:23:09.387435Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "# import os\n",
    "import time\n",
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from names import check, raw_data, vectorize, seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "### Read the data\n",
    "\n",
    "First, look in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:09.799308Z",
     "iopub.status.busy": "2021-06-16T15:23:09.798771Z",
     "iopub.status.idle": "2021-06-16T15:23:09.802851Z",
     "shell.execute_reply": "2021-06-16T15:23:09.802454Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 651954 characters\n"
     ]
    }
   ],
   "source": [
    "raw = raw_data.load_raw(\"../data/names.txt\")\n",
    "text = raw_data.join_raw(raw)\n",
    "vocab = vectorize.extract_vocab(text)\n",
    "\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adray Lasbard                                                                                       \\nAlbel Nox                                                                                           \\nCliff Fittir                                                                                      '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:09.806036Z",
     "iopub.status.busy": "2021-06-16T15:23:09.805502Z",
     "iopub.status.idle": "2021-06-16T15:23:09.807205Z",
     "shell.execute_reply": "2021-06-16T15:23:09.807599Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adray Lasbard                                                                                       \n",
      "Albel Nox                                                                                           \n",
      "Cliff Fittir                                    \n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:09.819578Z",
     "iopub.status.busy": "2021-06-16T15:23:09.819053Z",
     "iopub.status.idle": "2021-06-16T15:23:09.820995Z",
     "shell.execute_reply": "2021-06-16T15:23:09.821315Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = vectorize.extract_vocab(text)\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Process the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Vectorize the text\n",
    "\n",
    "Before training, you need to convert the strings to a numerical representation. \n",
    "\n",
    "The `preprocessing.StringLookup` layer can convert each character into a numeric ID. It just needs the text to be split into tokens first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.106489Z",
     "iopub.status.busy": "2021-06-16T15:23:11.105807Z",
     "iopub.status.idle": "2021-06-16T15:23:11.384611Z",
     "shell.execute_reply": "2021-06-16T15:23:11.383945Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = vectorize.unicode_split(example_texts)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorator = vectorize.Vectorator(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmX_jbgQqfOi"
   },
   "source": [
    "It converts form tokens to character IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.403321Z",
     "iopub.status.busy": "2021-06-16T15:23:11.402650Z",
     "iopub.status.idle": "2021-06-16T15:23:11.406461Z",
     "shell.execute_reply": "2021-06-16T15:23:11.406788Z"
    },
    "id": "WLv5Q_2TC2pc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 46, 47, 48, 49, 50, 51], [68, 69, 70]]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = vectorator.ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "Since the goal of this tutorial is to generate text, it will also be important to invert this representation and recover human-readable strings from it. For this you can use `preprocessing.StringLookup(..., invert=True)`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uenivzwqsDhp"
   },
   "source": [
    "Note: Here instead of passing the original vocabulary generated with `sorted(set(text))` use the `get_vocabulary()` method of the `preprocessing.StringLookup` layer so that the `[UNK]` tokens is set the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqTDDxS-s-H8"
   },
   "source": [
    "This layer recovers the characters from the vectors of IDs, and returns them as a `tf.RaggedTensor` of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.418750Z",
     "iopub.status.busy": "2021-06-16T15:23:11.418100Z",
     "iopub.status.idle": "2021-06-16T15:23:11.421360Z",
     "shell.execute_reply": "2021-06-16T15:23:11.421695Z"
    },
    "id": "c2GCh0ySD44s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = vectorator.chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "### The prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wssHQ1oGymwe"
   },
   "source": [
    "Given a character, or a sequence of characters, what is the most probable next character? This is the task you're training the model to perform. The input to the model will be a sequence of characters, and you train the model to predict the output—the following character at each time step.\n",
    "\n",
    "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Create training examples and targets\n",
    "\n",
    "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
    "\n",
    "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
    "\n",
    "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
    "\n",
    "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = vectorize.DataSet(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "The `batch` method lets you easily convert these individual characters to sequences of the desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "For training you'll need a dataset of `(input, label)` pairs. Where `input` and \n",
    "`label` are sequences. At each time step the input is the current character and the label is the next character. \n",
    "\n",
    "Here's a function that takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.963007Z",
     "iopub.status.busy": "2021-06-16T15:23:11.962343Z",
     "iopub.status.idle": "2021-06-16T15:23:11.965433Z",
     "shell.execute_reply": "2021-06-16T15:23:11.964994Z"
    },
    "id": "WxbDTJTw5u_P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize.split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Create training batches\n",
    "\n",
    "You used `tf.data` to split the text into manageable sequences. But before feeding this data into the model, you need to shuffle the data and pack it into batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Build The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "This section defines the model as a `keras.Model` subclass (For details see [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
    "\n",
    "This model has three layers:\n",
    "\n",
    "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map each character-ID to a vector with `embedding_dim` dimensions;\n",
    "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n",
    "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:12.044401Z",
     "iopub.status.busy": "2021-06-16T15:23:12.043777Z",
     "iopub.status.idle": "2021-06-16T15:23:12.045488Z",
     "shell.execute_reply": "2021-06-16T15:23:12.045828Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "# vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = [1024, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:12.057187Z",
     "iopub.status.busy": "2021-06-16T15:23:12.056553Z",
     "iopub.status.idle": "2021-06-16T15:23:12.066178Z",
     "shell.execute_reply": "2021-06-16T15:23:12.065730Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "model = seq_model.SeqModel(\n",
    "    seq_model.Hypers(\n",
    "        # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "        vocab_size=ds.vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        rnn_units=rnn_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkA5upJIJ7W7"
   },
   "source": [
    "For each character the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character:\n",
    "\n",
    "![A drawing of the data passing through the model](images/text_generation_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKbfm04amhXk"
   },
   "source": [
    "Note: For training you could use a `keras.Sequential` model here. To  generate text later you'll need to manage the RNN's internal state. It's simpler to include the state input and output options upfront, than it is to rearrange the model architecture later. For more details see the [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## Try the model\n",
    "\n",
    "Now run the model to see that it behaves as expected.\n",
    "\n",
    "First check the shape of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:12.070191Z",
     "iopub.status.busy": "2021-06-16T15:23:12.069612Z",
     "iopub.status.idle": "2021-06-16T15:23:14.644916Z",
     "shell.execute_reply": "2021-06-16T15:23:14.645260Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 79) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in ds.dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6NzLBi4VM4o"
   },
   "source": [
    "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.649909Z",
     "iopub.status.busy": "2021-06-16T15:23:14.649350Z",
     "iopub.status.idle": "2021-06-16T15:23:14.652204Z",
     "shell.execute_reply": "2021-06-16T15:23:14.652543Z"
    },
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  20224     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  4133376   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  60751     \n",
      "=================================================================\n",
      "Total params: 8,152,655\n",
      "Trainable params: 8,152,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "To get actual predictions from the model you need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
    "\n",
    "Note: It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.\n",
    "\n",
    "Try it for the first example in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.656316Z",
     "iopub.status.busy": "2021-06-16T15:23:14.655704Z",
     "iopub.status.idle": "2021-06-16T15:23:14.658423Z",
     "shell.execute_reply": "2021-06-16T15:23:14.658814Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "This gives us, at each timestep, a prediction of the next character index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.662823Z",
     "iopub.status.busy": "2021-06-16T15:23:14.662207Z",
     "iopub.status.idle": "2021-06-16T15:23:14.664468Z",
     "shell.execute_reply": "2021-06-16T15:23:14.664796Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 29, 56, 42, 42, 36, 14, 54, 32, 12, 39, 34, 28, 15, 50, 23, 11,\n",
       "       76, 41, 78, 54, 77,  5, 12, 21, 29, 29, 35,  4, 56, 71, 51, 33, 30,\n",
       "        3, 64, 67, 10, 68, 31, 26,  3, 32, 57, 38, 49, 12, 46, 36, 78, 49,\n",
       "       44,  6, 63, 58, 56, 64, 67, 37, 35, 52, 19, 69, 45, 70, 32, 23, 67,\n",
       "        5, 50, 17, 17, 37, 54, 45, 64, 27, 56, 71, 63,  0, 39, 63, 36, 49,\n",
       "       11, 11, 59, 72, 76, 53, 42, 70, 75, 34, 74, 67,  6, 70, 12],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "Decode these to see the text predicted by this untrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.668624Z",
     "iopub.status.busy": "2021-06-16T15:23:14.668019Z",
     "iopub.status.idle": "2021-06-16T15:23:14.672269Z",
     "shell.execute_reply": "2021-06-16T15:23:14.672602Z"
    },
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " ['Leila                                                                                               ']\n",
      "\n",
      "Next Char Predictions:\n",
      " [\"mKlXXR6jN3UPJ7fE2öWījā,3CKKQ'lÓgOL&tw1xMH&NmTe3bRīeZ-snltwSQhAyazNEw,f99SjatIlÓs[UNK]UsRe22oáöiXzóPíw-z3\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", ds.text_from_ids(np.array([input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", ds.text_from_ids(np.array([sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "### Attach an optimizer, and a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "The standard `tf.keras.losses.sparse_categorical_crossentropy` loss function works in this case because it is applied across the last dimension of the predictions.\n",
    "\n",
    "Because your model returns logits, you need to set the `from_logits` flag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.681665Z",
     "iopub.status.busy": "2021-06-16T15:23:14.681125Z",
     "iopub.status.idle": "2021-06-16T15:23:14.687262Z",
     "shell.execute_reply": "2021-06-16T15:23:14.686833Z"
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 79)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         4.3679676\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = model.loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkvUIneTFiow"
   },
   "source": [
    "A newly initialized model shouldn't be too sure of itself, the output logits should all have similar magnitudes. To confirm this you can check that the exponential of the mean loss is approximately equal to the vocabulary size. A much higher loss means the model is sure of its wrong answers, and is badly initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.690546Z",
     "iopub.status.busy": "2021-06-16T15:23:14.690018Z",
     "iopub.status.idle": "2021-06-16T15:23:14.693545Z",
     "shell.execute_reply": "2021-06-16T15:23:14.693089Z"
    },
    "id": "MAJfS5YoFiHf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.88315"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeOXriLcymww"
   },
   "source": [
    "Configure the training procedure using the `tf.keras.Model.compile` method. Use `tf.keras.optimizers.Adam` with default arguments and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.699890Z",
     "iopub.status.busy": "2021-06-16T15:23:14.699359Z",
     "iopub.status.idle": "2021-06-16T15:23:14.704390Z",
     "shell.execute_reply": "2021-06-16T15:23:14.703935Z"
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6XBUUavgF56"
   },
   "source": [
    "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = check.CheckPoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "To keep training time reasonable, use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.712994Z",
     "iopub.status.busy": "2021-06-16T15:23:14.712456Z",
     "iopub.status.idle": "2021-06-16T15:23:14.714281Z",
     "shell.execute_reply": "2021-06-16T15:23:14.714660Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.718215Z",
     "iopub.status.busy": "2021-06-16T15:23:14.717580Z",
     "iopub.status.idle": "2021-06-16T15:25:02.747960Z",
     "shell.execute_reply": "2021-06-16T15:25:02.747311Z"
    },
    "id": "UK-hmKjYVoll",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 10s 70ms/step - loss: 0.4968\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 0.3353\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 0.2987\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 8s 71ms/step - loss: 0.3024\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 8s 71ms/step - loss: 0.2775\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 8s 71ms/step - loss: 0.2773\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 8s 72ms/step - loss: 0.2683\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 8s 72ms/step - loss: 0.2653\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 8s 72ms/step - loss: 0.2597\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 8s 72ms/step - loss: 0.2568\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 8s 73ms/step - loss: 0.2579\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 8s 73ms/step - loss: 0.2459\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 8s 73ms/step - loss: 0.2348\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 8s 73ms/step - loss: 0.2264\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 8s 74ms/step - loss: 0.2250\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 8s 74ms/step - loss: 0.2014\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.1860\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.1791\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.1567\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.1461\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_with_chk(ds, checkpoint=chk, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIdQ8c8NvMzV"
   },
   "source": [
    "The simplest way to generate text with this model is to run it in a loop, and keep track of the model's internal state as you execute it.\n",
    "\n",
    "![To generate text the model's output is fed back to the input](images/text_generation_sampling.png)\n",
    "\n",
    "Each time you call the model you pass in some text and an internal state. The model returns a prediction for the next character and its new state. Pass the prediction and state back in to continue generating text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "The following makes a single step prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:02.761943Z",
     "iopub.status.busy": "2021-06-16T15:25:02.761350Z",
     "iopub.status.idle": "2021-06-16T15:25:02.767592Z",
     "shell.execute_reply": "2021-06-16T15:25:02.767096Z"
    },
    "id": "fqMOuDutnOxK"
   },
   "outputs": [],
   "source": [
    "one_step_model = seq_model.OneStep(model, vectorator=vectorator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9yDoa0G3IgQ"
   },
   "source": [
    "Run it in a loop to generate some text. Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:02.772943Z",
     "iopub.status.busy": "2021-06-16T15:25:02.772363Z",
     "iopub.status.idle": "2021-06-16T15:25:05.014954Z",
     "shell.execute_reply": "2021-06-16T15:25:05.015310Z"
    },
    "id": "ST7PSyk9t1mT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Romeo Huard                                                                                               ']\n",
      "\n",
      "Run time: 1.3441846370697021\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = one_step_model.generate(['Romeo '], 100)\n",
    "end = time.time()\n",
    "print(result)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "The easiest thing you can do to improve the results is to train it for longer (try `EPOCHS = 30`).\n",
    "\n",
    "You can also experiment with a different start string, try adding another RNN layer to improve the model's accuracy, or adjust the temperature parameter to generate more or less random predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OfbI4aULmuj"
   },
   "source": [
    "If you want the model to generate text *faster* the easiest thing you can do is batch the text generation. In the example below the model generates 5 outputs in about the same time it took to generate 1 above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:05.021167Z",
     "iopub.status.busy": "2021-06-16T15:25:05.020608Z",
     "iopub.status.idle": "2021-06-16T15:25:07.138137Z",
     "shell.execute_reply": "2021-06-16T15:25:07.138522Z"
    },
    "id": "ZkLu7Y8UCMT7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qian\n",
      "Witru                                                                                            \n",
      "cha\n",
      "Emerica Malenai\n",
      "Raveris Bros. series\n",
      "Tristan\n",
      "Yuna\n",
      "Ungel\n",
      "Iscif Sige\n",
      "Osri and\n",
      "Prince of Huild\n",
      "Anna\n",
      "Sevina\n",
      "Daghon\n",
      "Four Lie's Father                                                                           \n",
      "cha\n",
      "Golde\n",
      "Heme Zoodles\n",
      "Jatakh Trodelle\n",
      "Kutheyak\n",
      "Link\n",
      "Zanpo\n",
      "Xpunnyrin                                                                  \n",
      "r\n",
      "Cheda\n",
      "Valif\n",
      "Boto\n",
      "Nagal Samare\n",
      "Mogato\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 1.38372802734375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "result = one_step_model.generate(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"), 100)\n",
    "end = time.time()\n",
    "for line in result:\n",
    "    print(line.strip())\n",
    "print('\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlUQzwu6EXam"
   },
   "source": [
    "## Export the generator\n",
    "\n",
    "This single-step model can easily be [saved and restored](https://www.tensorflow.org/guide/saved_model), allowing you to use it anywhere a `tf.saved_model` is accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:07.142739Z",
     "iopub.status.busy": "2021-06-16T15:25:07.142196Z",
     "iopub.status.idle": "2021-06-16T15:25:13.133633Z",
     "shell.execute_reply": "2021-06-16T15:25:13.133109Z"
    },
    "id": "3Grk32H_CzsC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rbras\\repos\\names\\notebooks\\seq_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\rbras\\repos\\names\\notebooks\\seq_model\\assets\n"
     ]
    }
   ],
   "source": [
    "chk.save(vocab, model)\n",
    "restored = chk.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\n',\n",
       "  ' ',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '/',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '?',\n",
       "  'A',\n",
       "  'B',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'J',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'U',\n",
       "  'V',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'Z',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z',\n",
       "  'Ó',\n",
       "  'á',\n",
       "  'é',\n",
       "  'í',\n",
       "  'ó',\n",
       "  'ö',\n",
       "  'ā',\n",
       "  'ī'],\n",
       " <names.vectorize.Vectorator at 0x21de6148be0>,\n",
       " <tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x21dfb292460>,\n",
       " <names.seq_model.OneStep at 0x21dfabe2e20>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<names.seq_model.OneStep at 0x21dfabe2e20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.139970Z",
     "iopub.status.busy": "2021-06-16T15:25:13.139254Z",
     "iopub.status.idle": "2021-06-16T15:25:13.449381Z",
     "shell.execute_reply": "2021-06-16T15:25:13.449729Z"
    },
    "id": "_Z9bb_wX6Uuu",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\rbras\\repos\\names\\names\\seq_model.py:129 generate_one_step  *\n        predicted_logits, states = self.model(\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:670 _call_attribute  **\n        return instance.__call__(*args, **kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889 __call__\n        result = self._call(*args, **kwds)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933 _call\n        self._initialize(args, kwds, add_initializers_to=initializers)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:763 _initialize\n        self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3050 _get_concrete_function_internal_garbage_collected\n        graph_function, _ = self._maybe_define_function(args, kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3444 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3279 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:999 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:672 wrapped_fn\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:285 restored_function_body\n        raise ValueError(\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (4 total):\n        * Tensor(\"inputs:0\", shape=(26, None), dtype=int64)\n        * None\n        * True\n        * False\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='input_1')\n        * None\n        * False\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='inputs')\n        * None\n        * False\n        * False\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='inputs')\n        * None\n        * False\n        * True\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='input_1')\n        * None\n        * False\n        * True\n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5641714ece18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestored\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"QWERTYUIOPASDFGHJKLZXCVBNM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rbras\\repos\\names\\names\\seq_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, first_chars, n)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[0mnext_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3969\u001b[0m     \u001b[1;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3970\u001b[0m     \u001b[1;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3971\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3972\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\rbras\\repos\\names\\names\\seq_model.py:129 generate_one_step  *\n        predicted_logits, states = self.model(\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:670 _call_attribute  **\n        return instance.__call__(*args, **kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889 __call__\n        result = self._call(*args, **kwds)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933 _call\n        self._initialize(args, kwds, add_initializers_to=initializers)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:763 _initialize\n        self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3050 _get_concrete_function_internal_garbage_collected\n        graph_function, _ = self._maybe_define_function(args, kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3444 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3279 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:999 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:672 wrapped_fn\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:285 restored_function_body\n        raise ValueError(\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (4 total):\n        * Tensor(\"inputs:0\", shape=(26, None), dtype=int64)\n        * None\n        * True\n        * False\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='input_1')\n        * None\n        * False\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='inputs')\n        * None\n        * False\n        * False\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='inputs')\n        * None\n        * False\n        * True\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 100), dtype=tf.int64, name='input_1')\n        * None\n        * False\n        * True\n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "result = restored[-1].generate(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"), 100)\n",
    "end = time.time()\n",
    "for line in result:\n",
    "    print(line)\n",
    "print('\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## Advanced: Customized Training\n",
    "\n",
    "The above training procedure is simple, but does not give you much control.\n",
    "It uses teacher-forcing which prevents bad predictions from being fed back to the model, so the model never learns to recover from mistakes.\n",
    "\n",
    "So now that you've seen how to run the model manually next you'll implement the training loop. This gives a starting point if, for example, you want to implement _curriculum  learning_ to help stabilize the model's open-loop output.\n",
    "\n",
    "The most important part of a custom training loop is the train step function.\n",
    "\n",
    "Use `tf.GradientTape` to track the gradients. You can learn more about this approach by reading the [eager execution guide](https://www.tensorflow.org/guide/eager).\n",
    "\n",
    "The basic procedure is:\n",
    "\n",
    "1. Execute the model and calculate the loss under a `tf.GradientTape`.\n",
    "2. Calculate the updates and apply them to the model using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.455005Z",
     "iopub.status.busy": "2021-06-16T15:25:13.454208Z",
     "iopub.status.idle": "2021-06-16T15:25:13.456512Z",
     "shell.execute_reply": "2021-06-16T15:25:13.456079Z"
    },
    "id": "x0pZ101hjwW0"
   },
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Oc-eJALcK8B"
   },
   "source": [
    "The above implementation of the `train_step` method follows [Keras' `train_step` conventions](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). This is optional, but it allows you to change the behavior of the train step and still use keras' `Model.compile` and `Model.fit` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.461477Z",
     "iopub.status.busy": "2021-06-16T15:25:13.460619Z",
     "iopub.status.idle": "2021-06-16T15:25:13.466301Z",
     "shell.execute_reply": "2021-06-16T15:25:13.466645Z"
    },
    "id": "XKyWiZ_Lj7w5"
   },
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.472720Z",
     "iopub.status.busy": "2021-06-16T15:25:13.471525Z",
     "iopub.status.idle": "2021-06-16T15:25:13.475448Z",
     "shell.execute_reply": "2021-06-16T15:25:13.475016Z"
    },
    "id": "U817KUm7knlm"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.479322Z",
     "iopub.status.busy": "2021-06-16T15:25:13.478412Z",
     "iopub.status.idle": "2021-06-16T15:25:20.421343Z",
     "shell.execute_reply": "2021-06-16T15:25:20.420880Z"
    },
    "id": "o694aoBPnEi9"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8nAtKHVoInR"
   },
   "source": [
    "Or if you need more control, you can write your own complete custom training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:20.428870Z",
     "iopub.status.busy": "2021-06-16T15:25:20.428217Z",
     "iopub.status.idle": "2021-06-16T15:26:14.285123Z",
     "shell.execute_reply": "2021-06-16T15:26:14.285463Z"
    },
    "id": "d4tSNwymzf-q",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "mean = tf.metrics.Mean()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    mean.reset_states()\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = model.train_step([inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "\n",
    "        if batch_n % 50 == 0:\n",
    "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
    "            print(template)\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print()\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
    "    print(\"_\"*80)\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"))\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(40):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"))\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(40):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "result = [\" \".join([a.strip() for a in name.decode(\"utf-8\").split() if len(a)]) for name in result.numpy()]\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(stem=\"\", n=1):\n",
    "    names = []\n",
    "    for _ in range(n):\n",
    "        states = None\n",
    "        next_char = [stem + ch for ch in \"QWERTYUIOPASDFGHJKLZXCVBNM\"]\n",
    "        next_char = tf.constant(next_char)\n",
    "        result = [next_char]\n",
    "\n",
    "        for n in range(40):\n",
    "          next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "          result.append(next_char)\n",
    "\n",
    "        result = tf.strings.join(result)\n",
    "        names += [\" \".join([a.strip() for a in name.decode(\"utf-8\").split() if len(a)]) for name in result.numpy()]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quale',\n",
       " 'Weapon Sellers',\n",
       " 'Erin',\n",
       " 'Razf',\n",
       " 'Tatamie Aleamas',\n",
       " 'Yeta',\n",
       " 'Upt',\n",
       " 'Ikona',\n",
       " 'Opops of Spirit',\n",
       " 'Puffy',\n",
       " 'Anja',\n",
       " 'Siword',\n",
       " 'Dark Waral',\n",
       " 'Fira Birk',\n",
       " 'Goron Thild',\n",
       " 'Henhald',\n",
       " 'Jesse Zelkain',\n",
       " \"Kiore d'hrelliet\",\n",
       " 'Leodorn',\n",
       " \"Zahn'malal\",\n",
       " 'Xda Wylader',\n",
       " 'Ciaco Lacuha',\n",
       " 'Vicks',\n",
       " 'Blacktman',\n",
       " 'Nyne',\n",
       " 'Mailia Uldencuta',\n",
       " 'Quinfort',\n",
       " 'Wasta Order Mimaga',\n",
       " 'Evelerict Untersunny',\n",
       " 'Ricard',\n",
       " 'Tika Blunhacia',\n",
       " 'Yabal',\n",
       " 'Uriang Horen',\n",
       " 'Istreda',\n",
       " 'Owron',\n",
       " 'Pira',\n",
       " 'Anberu',\n",
       " 'Stal',\n",
       " 'Despo',\n",
       " 'Fenralia',\n",
       " 'Gilgamesh',\n",
       " 'Harvit',\n",
       " 'Jabkielle',\n",
       " 'Kumaza',\n",
       " 'Link',\n",
       " \"Zidameth I'narimia\",\n",
       " \"X'vebbe\",\n",
       " 'Chai-',\n",
       " 'Vaken',\n",
       " 'Bldig',\n",
       " \"N'aeLi Ya\",\n",
       " 'Mako',\n",
       " 'Quincemort de Leigacuin',\n",
       " 'Wize Gublo',\n",
       " 'Emmers of Estrim',\n",
       " 'Radavana',\n",
       " 'Trostles',\n",
       " 'Ynow',\n",
       " 'Uster',\n",
       " 'Ignatius',\n",
       " \"Old's Fither\",\n",
       " 'Peppita Rossetti',\n",
       " 'Azmul',\n",
       " 'Schamatte',\n",
       " 'Diria',\n",
       " 'Frayn Mage',\n",
       " 'Grons',\n",
       " 'Hevd',\n",
       " 'Jysoke',\n",
       " 'Khee',\n",
       " 'Linza',\n",
       " 'Zec ta Blift',\n",
       " 'Xak',\n",
       " 'Cocobusi',\n",
       " 'Varst',\n",
       " 'Baddi',\n",
       " \"Ny'arhle\",\n",
       " 'Momodima',\n",
       " 'Quinfost Iftra',\n",
       " 'WrDys',\n",
       " 'Echigra Mindo',\n",
       " 'Roperris',\n",
       " \"Tinkle's Patentes\",\n",
       " 'Yama Yahga',\n",
       " 'Unir',\n",
       " 'Il Zuman',\n",
       " 'Oriane',\n",
       " 'Photo',\n",
       " 'Ambra',\n",
       " 'Shamonde',\n",
       " 'Dr. Lugae',\n",
       " 'Fairy andereil Helkig',\n",
       " 'Gian',\n",
       " 'Higo',\n",
       " 'Jene',\n",
       " 'Kuja',\n",
       " 'Lady Auburnbrie',\n",
       " 'Zoah vanbackball',\n",
       " 'Xunarus Nanandal',\n",
       " 'Clase Kelsa',\n",
       " 'Venet',\n",
       " 'Bunrio',\n",
       " 'Natch',\n",
       " 'Mercus',\n",
       " 'Quinffild Allthoughts',\n",
       " 'Welch Vineyard',\n",
       " 'Edel',\n",
       " 'Ratarok',\n",
       " 'Tunsis',\n",
       " 'Yunafneya',\n",
       " 'Urianger Buncs',\n",
       " 'Indech',\n",
       " 'Oroo',\n",
       " 'Pain',\n",
       " 'Adraine Leveilleur',\n",
       " 'Santa',\n",
       " 'Darchige',\n",
       " 'Flasha',\n",
       " 'General Madelene',\n",
       " 'Heont',\n",
       " 'Jiamato Madison',\n",
       " 'Kijah Rogai',\n",
       " 'Liok',\n",
       " 'Zanla',\n",
       " 'Xlasie',\n",
       " 'Cid Kirrborne',\n",
       " 'Vuöris',\n",
       " 'Burton',\n",
       " 'Naima',\n",
       " 'Maeya',\n",
       " 'Qnoatin',\n",
       " 'Watts',\n",
       " 'Edlain de Forobect',\n",
       " 'Raft',\n",
       " 'Tonari',\n",
       " 'Yeca',\n",
       " 'Urikia',\n",
       " 'Indector Sibetrik',\n",
       " 'Orvan',\n",
       " 'Peoss',\n",
       " 'Azahlia',\n",
       " 'Swade King',\n",
       " 'Darka',\n",
       " 'Final Fantasy IVcharacters',\n",
       " 'Gackeh',\n",
       " 'Hinor',\n",
       " 'Jaka',\n",
       " 'Klue',\n",
       " 'Lain',\n",
       " 'Zunan',\n",
       " 'Xlade',\n",
       " 'Chapuk',\n",
       " 'Vicerva',\n",
       " 'Biggs and Wedge',\n",
       " 'Numuti',\n",
       " 'Melina',\n",
       " 'Quinfort',\n",
       " 'Welch Vineyard',\n",
       " 'Edessar',\n",
       " 'Raviane',\n",
       " 'Tah Koraga',\n",
       " 'Yark Waltz',\n",
       " 'Unse',\n",
       " 'Itolydormeir Guado',\n",
       " \"Old Man 'Hencin\",\n",
       " 'Pevine Jiande',\n",
       " 'An Ladd of triba',\n",
       " 'Sumire',\n",
       " 'Durina',\n",
       " 'Frederick',\n",
       " 'Gessho',\n",
       " 'Hargs',\n",
       " 'Jenelk e',\n",
       " 'Kipi',\n",
       " 'Logi',\n",
       " \"Zhi'a\",\n",
       " 'Xoande',\n",
       " 'Celin',\n",
       " 'Victor Oakville',\n",
       " 'Biggs and Wedge',\n",
       " 'Nael Emofing',\n",
       " 'M uian',\n",
       " 'Quaple Naibaurin',\n",
       " 'WUrtb Shop Oeegrel',\n",
       " 'Evo',\n",
       " 'Rekia',\n",
       " 'Ticha',\n",
       " 'Yverla de Chepuen',\n",
       " 'Ulber',\n",
       " 'Inos da Fleureck',\n",
       " 'Orphan',\n",
       " 'Pida',\n",
       " 'Ashni',\n",
       " 'Seak o',\n",
       " 'Dah Guado',\n",
       " 'Forsuhi',\n",
       " 'Goacen',\n",
       " 'Hunniba',\n",
       " 'Jille Dradenard',\n",
       " 'Kosts',\n",
       " 'Leofard Myste',\n",
       " 'Zanan',\n",
       " 'Xofe Mosi',\n",
       " 'Capell',\n",
       " 'Vaide',\n",
       " 'Biggs and Wedge',\n",
       " 'Nulevai',\n",
       " 'Micara',\n",
       " 'Queen of the Triffin',\n",
       " 'Waitrescen',\n",
       " 'Eshalias',\n",
       " 'Roire Leodiga',\n",
       " 'Tigannberg Links',\n",
       " 'Yuria Tionysus',\n",
       " 'Usper',\n",
       " 'Izpe',\n",
       " 'Ospaccia',\n",
       " \"Photol B'aram Dala\",\n",
       " 'Ampria',\n",
       " 'Shikamie M M',\n",
       " 'Doza',\n",
       " 'Fuck',\n",
       " 'Gibbs and Dewen',\n",
       " 'Hiamu',\n",
       " 'Jewvan',\n",
       " 'Kento',\n",
       " 'Leof',\n",
       " 'Zedericia',\n",
       " 'Xzv-',\n",
       " 'Carrill',\n",
       " 'Vincent Valentine',\n",
       " 'Baige',\n",
       " 'Nagur',\n",
       " 'Moorage Cornediat',\n",
       " 'Qulute Calise',\n",
       " 'Worke',\n",
       " 'Evellist Manke',\n",
       " 'Riko',\n",
       " 'Tink',\n",
       " 'Yovine',\n",
       " 'Ulia Hifiberk',\n",
       " 'Ilveigze',\n",
       " 'Owep Balethin',\n",
       " 'Preissa',\n",
       " 'Atareftus',\n",
       " 'Stanice',\n",
       " 'Dunstan',\n",
       " 'Final Leetyl',\n",
       " 'Gan',\n",
       " 'Holland',\n",
       " 'Julece',\n",
       " 'Kiana',\n",
       " 'Lucia',\n",
       " 'Zaka',\n",
       " 'X Gunber',\n",
       " 'Coro',\n",
       " 'Vethyna',\n",
       " 'Blair Lansfeld',\n",
       " 'Necron',\n",
       " 'Magoron']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joby of Quon',\n",
       " 'Joby of Windebrance',\n",
       " 'Joby of Ebbatt',\n",
       " 'Joby of Risian',\n",
       " 'Joby of Tibelan',\n",
       " 'Joby of Yeingagi',\n",
       " 'Joby of Ubize',\n",
       " 'Joby of Itcheina',\n",
       " 'Joby of Obingo',\n",
       " 'Joby of Pinia',\n",
       " 'Joby of Astral',\n",
       " 'Joby of Shinro',\n",
       " 'Joby of Dernneets',\n",
       " 'Joby of Fithgera',\n",
       " 'Joby of Goron',\n",
       " 'Joby of Hinksmi',\n",
       " 'Joby of Junsels',\n",
       " 'Joby of Kinneis',\n",
       " 'Joby of Light',\n",
       " 'Joby of Zhina',\n",
       " 'Joby of XII',\n",
       " 'Joby of Chist',\n",
       " 'Joby of Vinkers',\n",
       " \"Joby of B'rargin\",\n",
       " 'Joby of Nestracia',\n",
       " 'Joby of Motica',\n",
       " 'Joby of Qeon',\n",
       " 'Joby of Wabaa',\n",
       " 'Joby of Eulmore',\n",
       " 'Joby of Rustie',\n",
       " 'Joby of Tinderbird',\n",
       " 'Joby of Yibba',\n",
       " 'Joby of Underling',\n",
       " 'Joby of Iron Parooh',\n",
       " 'Joby of Oav',\n",
       " 'Joby of Pohi',\n",
       " 'Joby of All',\n",
       " 'Joby of Siserukk',\n",
       " 'Joby of Dewen',\n",
       " 'Joby of Forien',\n",
       " 'Joby of Garon',\n",
       " 'Joby of Hirrbeld',\n",
       " 'Joby of Jeamir',\n",
       " 'Joby of Kinnberd',\n",
       " 'Joby of Legin',\n",
       " 'Joby of Zew',\n",
       " 'Joby of Xe Habbaure',\n",
       " 'Joby of Cornevia',\n",
       " 'Joby of Vinkers',\n",
       " 'Joby of Bimber',\n",
       " 'Joby of Nan',\n",
       " 'Joby of Ming',\n",
       " 'Joby of Quel',\n",
       " 'Joby of Winch',\n",
       " 'Joby of Eil',\n",
       " 'Joby of Rist',\n",
       " 'Joby of Tiben',\n",
       " 'Joby of Yurin',\n",
       " 'Joby of Undiole',\n",
       " 'Joby of Id Aliapop',\n",
       " 'Joby of Ovi and Biranimi',\n",
       " 'Joby of Phan of Fish',\n",
       " 'Joby of Auburn',\n",
       " 'Joby of Spline',\n",
       " 'Joby of Doren',\n",
       " 'Joby of Fubalian',\n",
       " 'Joby of Gordand',\n",
       " 'Joby of Heibwin',\n",
       " 'Joby of Jugi',\n",
       " 'Joby of Kinner',\n",
       " 'Joby of Lyng Astled',\n",
       " 'Joby of Zelba',\n",
       " 'Joby of XII',\n",
       " 'Joby of Cornelia',\n",
       " 'Joby of Viston',\n",
       " 'Joby of Burmecia',\n",
       " 'Joby of Nosgleara',\n",
       " 'Joby of Miro',\n",
       " 'Joby of Queger',\n",
       " 'Joby of Wigasa',\n",
       " 'Joby of En ibiapi',\n",
       " 'Joby of Robalag',\n",
       " 'Joby of Time',\n",
       " 'Joby of Yaboka',\n",
       " 'Joby of Umomito',\n",
       " 'Joby of Iminising',\n",
       " 'Joby of Osir',\n",
       " 'Joby of Phimas',\n",
       " 'Joby of Astrin',\n",
       " 'Joby of Shailam',\n",
       " 'Joby of Din',\n",
       " 'Joby of Fints',\n",
       " 'Joby of Goildebrand',\n",
       " 'Joby of Hugen',\n",
       " 'Joby of Jiggo',\n",
       " 'Joby of Kinnshint',\n",
       " 'Joby of Leingod',\n",
       " 'Joby of Zew',\n",
       " 'Joby of XI Scaevain',\n",
       " 'Joby of Carily',\n",
       " 'Joby of Viniaine',\n",
       " 'Joby of Bail',\n",
       " 'Joby of Neifb',\n",
       " 'Joby of Misters',\n",
       " 'Joby of Qions',\n",
       " 'Joby of Windem',\n",
       " 'Joby of Eag',\n",
       " 'Joby of Recort',\n",
       " 'Joby of Timba',\n",
       " 'Joby of Yus',\n",
       " 'Joby of Underlorn',\n",
       " 'Joby of Iw',\n",
       " 'Joby of Oigr',\n",
       " 'Joby of Phos',\n",
       " 'Joby of Astrim',\n",
       " 'Joby of Shinder',\n",
       " 'Joby of Dering',\n",
       " 'Joby of Forlin',\n",
       " 'Joby of Giott',\n",
       " 'Joby of Higbal',\n",
       " 'Joby of Jeiobbs',\n",
       " 'Joby of Kinnes',\n",
       " 'Joby of Licias',\n",
       " 'Joby of Zhiefbald',\n",
       " \"Joby of X'Orengain\",\n",
       " 'Joby of Cornelia',\n",
       " 'Joby of Vechra',\n",
       " 'Joby of Boron',\n",
       " 'Joby of Nigia Beshten',\n",
       " 'Joby of Meisain',\n",
       " 'Joby of Quen',\n",
       " 'Joby of Wimbi',\n",
       " 'Joby of Eith',\n",
       " 'Joby of Reswendr',\n",
       " 'Joby of Timer',\n",
       " 'Joby of Yoil',\n",
       " 'Joby of Underling',\n",
       " 'Joby of Inborla',\n",
       " 'Joby of Obbera',\n",
       " 'Joby of Pitmelly',\n",
       " 'Joby of Astina',\n",
       " 'Joby of Spirutia',\n",
       " 'Joby of Dind Fiad',\n",
       " 'Joby of Fyralia',\n",
       " 'Joby of Garon',\n",
       " 'Joby of Hingen',\n",
       " 'Joby of Junis',\n",
       " 'Joby of Kinnbhoos',\n",
       " 'Joby of Light',\n",
       " 'Joby of Zow',\n",
       " 'Joby of XI',\n",
       " 'Joby of Coribi',\n",
       " 'Joby of Vinkes',\n",
       " 'Joby of Bird',\n",
       " 'Joby of Nimia',\n",
       " 'Joby of Migi',\n",
       " 'Joby of Quenne',\n",
       " 'Joby of Wirden',\n",
       " 'Joby of Eedle',\n",
       " 'Joby of Racini',\n",
       " 'Joby of Time Mouilepharia',\n",
       " 'Joby of Yiem',\n",
       " 'Joby of Unsteim',\n",
       " 'Joby of Iind',\n",
       " 'Joby of Obinalant',\n",
       " 'Joby of Pintis',\n",
       " 'Joby of Astral',\n",
       " 'Joby of Silvalent',\n",
       " 'Joby of Difel',\n",
       " 'Joby of Fliers',\n",
       " 'Joby of Giont',\n",
       " 'Joby of Heast',\n",
       " 'Joby of Jubile',\n",
       " 'Joby of Kinness',\n",
       " 'Joby of Linf',\n",
       " 'Joby of Zen Alphant',\n",
       " 'Joby of XVII',\n",
       " 'Joby of Cornelia',\n",
       " 'Joby of Vighwind',\n",
       " \"Joby of B'rargin Dalmasca\",\n",
       " 'Joby of New',\n",
       " 'Joby of Mint',\n",
       " 'Joby of Que',\n",
       " 'Joby of Whial',\n",
       " 'Joby of Eigrers',\n",
       " 'Joby of Rhin',\n",
       " 'Joby of Tiblbart',\n",
       " 'Joby of Yutih',\n",
       " 'Joby of Undilia',\n",
       " 'Joby of Ind',\n",
       " 'Joby of Oseris',\n",
       " 'Joby of Phila',\n",
       " 'Joby of Asti',\n",
       " 'Joby of Silvalant',\n",
       " 'Joby of Dibennain',\n",
       " 'Joby of Fainis',\n",
       " 'Joby of Guild',\n",
       " 'Joby of Hillbornsyn',\n",
       " 'Joby of Jainbe',\n",
       " 'Joby of Kinners',\n",
       " 'Joby of Lackers',\n",
       " 'Joby of Zig',\n",
       " 'Joby of XII',\n",
       " 'Joby of Cornelia',\n",
       " 'Joby of Vinki',\n",
       " 'Joby of Bird',\n",
       " 'Joby of N',\n",
       " 'Joby of Minnas',\n",
       " 'Joby of Queen',\n",
       " 'Joby of Wibadaine',\n",
       " 'Joby of Elidiss',\n",
       " 'Joby of Rocie',\n",
       " 'Joby of Tibedrik',\n",
       " 'Joby of Yug',\n",
       " 'Joby of Ui',\n",
       " 'Joby of Indore IV',\n",
       " 'Joby of Oen',\n",
       " 'Joby of Phila',\n",
       " 'Joby of Astram',\n",
       " 'Joby of Silvrose',\n",
       " 'Joby of Denner',\n",
       " 'Joby of Fiter',\n",
       " 'Joby of Gurde',\n",
       " 'Joby of Highwind',\n",
       " 'Joby of Jua iel',\n",
       " 'Joby of Kidbes',\n",
       " 'Joby of Legaine',\n",
       " 'Joby of Zogin',\n",
       " 'Joby of XV',\n",
       " 'Joby of Corneria',\n",
       " 'Joby of Vinkerbark',\n",
       " 'Joby of Broling',\n",
       " 'Joby of Nuk',\n",
       " 'Joby of Mind',\n",
       " 'Joby of Qesen',\n",
       " 'Joby of Windsincent',\n",
       " 'Joby of Endiribe',\n",
       " 'Joby of Rhos',\n",
       " 'Joby of Tiller',\n",
       " 'Joby of Yoph Owner',\n",
       " 'Joby of Undinone',\n",
       " 'Joby of Indor Izonhi',\n",
       " 'Joby of Owin',\n",
       " 'Joby of Phisas',\n",
       " 'Joby of Astrelt',\n",
       " 'Joby of Silverlak',\n",
       " 'Joby of Denniett',\n",
       " 'Joby of Fobol',\n",
       " 'Joby of Gurobe',\n",
       " 'Joby of Highwind',\n",
       " 'Joby of Juhgles',\n",
       " 'Joby of Kenne',\n",
       " 'Joby of Ligat',\n",
       " 'Joby of Zonnklien',\n",
       " 'Joby of Xe Iranco',\n",
       " 'Joby of Corile',\n",
       " 'Joby of Vynus',\n",
       " 'Joby of Bin',\n",
       " 'Joby of Nege',\n",
       " 'Joby of Migna']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names('Joby of ', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joby the Queper',\n",
       " 'Joby the Wetaton',\n",
       " 'Joby the Ebirairi',\n",
       " 'Joby the Rosancelesca',\n",
       " 'Joby the Triforch',\n",
       " \"Joby the Y'Oragin\",\n",
       " 'Joby the UnPuilder',\n",
       " 'Joby the Ingerus',\n",
       " 'Joby the Ornitier',\n",
       " 'Joby the Potoluk',\n",
       " 'Joby the Alberion',\n",
       " 'Joby the Scaeva',\n",
       " 'Joby the Daibus',\n",
       " 'Joby the Faniuin',\n",
       " 'Joby the Godon om In Aliapon',\n",
       " 'Joby the Hatesaine',\n",
       " 'Joby the Jobagabie',\n",
       " 'Joby the Korgrach',\n",
       " 'Joby the Loipecarte',\n",
       " 'Joby the Zeime',\n",
       " 'Joby the XIIm',\n",
       " 'Joby the Courcillah',\n",
       " 'Joby the Vexitin',\n",
       " 'Joby the Bakeur',\n",
       " 'Joby the Nougecarpe',\n",
       " 'Joby the Maibo']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names('Joby the ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "place = []\n",
    "for name in generate_names():\n",
    "    name = name.split()[0]\n",
    "    for long_name in generate_names(name + \" of \"):\n",
    "        print(long_name)\n",
    "        place.append(long_name.split()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = list(filter(lambda name: name[0] == \"G\", place))\n",
    "G.sort()\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(place, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(place, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(place, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_model = seq_model.SeqModel(model.hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 79) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "foo_model.load_weights(\"foo\", by_name=False)\n",
    "for input_example_batch, target_example_batch in ds.dataset.take(1):\n",
    "    example_batch_predictions = foo_model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:799 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:530 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:630 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:75 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['seq_model_6/embedding_6/embeddings:0', 'seq_model_6/gru_12/gru_cell_12/kernel:0', 'seq_model_6/gru_12/gru_cell_12/recurrent_kernel:0', 'seq_model_6/gru_12/gru_cell_12/bias:0', 'seq_model_6/gru_13/gru_cell_13/kernel:0', 'seq_model_6/gru_13/gru_cell_13/recurrent_kernel:0', 'seq_model_6/gru_13/gru_cell_13/bias:0', 'seq_model_6/dense_6/kernel:0', 'seq_model_6/dense_6/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-e60c01a57780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfoo_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:799 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:530 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:630 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    C:\\Users\\rbras\\.conda\\envs\\names\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:75 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['seq_model_6/embedding_6/embeddings:0', 'seq_model_6/gru_12/gru_cell_12/kernel:0', 'seq_model_6/gru_12/gru_cell_12/recurrent_kernel:0', 'seq_model_6/gru_12/gru_cell_12/bias:0', 'seq_model_6/gru_13/gru_cell_13/kernel:0', 'seq_model_6/gru_13/gru_cell_13/recurrent_kernel:0', 'seq_model_6/gru_13/gru_cell_13/bias:0', 'seq_model_6/dense_6/kernel:0', 'seq_model_6/dense_6/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "foo_model.fit(ds.dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      multiple                  20224     \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 multiple                  4133376   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  60751     \n",
      "=================================================================\n",
      "Total params: 8,152,655\n",
      "Trainable params: 8,152,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "foo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  20224     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  4133376   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  60751     \n",
      "=================================================================\n",
      "Total params: 8,152,655\n",
      "Trainable params: 8,152,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
