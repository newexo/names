{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t09eeeR5prIJ"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:08.010073Z",
     "iopub.status.busy": "2021-06-16T15:23:08.009523Z",
     "iopub.status.idle": "2021-06-16T15:23:08.011747Z",
     "shell.execute_reply": "2021-06-16T15:23:08.011282Z"
    },
    "id": "GCCk8_dHpuNf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# Text generation with an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcD2nPQvPOFM"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwpJ5IffzRG6"
   },
   "source": [
    "This tutorial demonstrates how to generate text using a character-based RNN. You will work with a dataset of Shakespeare's writing from Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Given a sequence of characters from this data (\"Shakespear\"), train a model to predict the next character in the sequence (\"e\"). Longer sequences of text can be generated by calling the model repeatedly.\n",
    "\n",
    "Note: Enable GPU acceleration to execute this notebook faster. In Colab: *Runtime > Change runtime type > Hardware accelerator > GPU*.\n",
    "\n",
    "This tutorial includes runnable code implemented using [tf.keras](https://www.tensorflow.org/guide/keras/sequential_model) and [eager execution](https://www.tensorflow.org/guide/eager). The following is the sample output when the model in this tutorial trained for 30 epochs, and started with the prompt \"Q\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcygKkEVZBaa"
   },
   "source": [
    "<pre>\n",
    "QUEENE:\n",
    "I had thought thou hadst a Roman; for the oracle,\n",
    "Thus by All bids the man against the word,\n",
    "Which are so weak of care, by old care done;\n",
    "Your children were in your holy love,\n",
    "And the precipitation through the bleeding throne.\n",
    "\n",
    "BISHOP OF ELY:\n",
    "Marry, and will, my lord, to weep in such a one were prettiest;\n",
    "Yet now I was adopted heir\n",
    "Of the world's lamentable day,\n",
    "To watch the next way with his father with his face?\n",
    "\n",
    "ESCALUS:\n",
    "The cause why then we are all resolved more sons.\n",
    "\n",
    "VOLUMNIA:\n",
    "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
    "And love and pale as any will to that word.\n",
    "\n",
    "QUEEN ELIZABETH:\n",
    "But how long have I heard the soul for this world,\n",
    "And show his hands of life be proved to stand.\n",
    "\n",
    "PETRUCHIO:\n",
    "I say he look'd on, if I must be content\n",
    "To stay him from the fatal of our country's bliss.\n",
    "His lordship pluck'd from this sentence then for prey,\n",
    "And then let us twain, being the moon,\n",
    "were she such a case as fills m\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bGsCP9DZFQ5"
   },
   "source": [
    "While some of the sentences are grammatical, most do not make sense. The model has not learned the meaning of words, but consider:\n",
    "\n",
    "* The model is character-based. When training started, the model did not know how to spell an English word, or that words were even a unit of text.\n",
    "\n",
    "* The structure of the output resembles a play—blocks of text generally begin with a speaker name, in all capital letters similar to the dataset.\n",
    "\n",
    "* As demonstrated below, the model is trained on small batches of text (100 characters each), and is still able to generate a longer sequence of text with coherent structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:08.018637Z",
     "iopub.status.busy": "2021-06-16T15:23:08.018060Z",
     "iopub.status.idle": "2021-06-16T15:23:09.387014Z",
     "shell.execute_reply": "2021-06-16T15:23:09.387435Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from names import raw_data, vectorize, seq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "### Read the data\n",
    "\n",
    "First, look in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:09.799308Z",
     "iopub.status.busy": "2021-06-16T15:23:09.798771Z",
     "iopub.status.idle": "2021-06-16T15:23:09.802851Z",
     "shell.execute_reply": "2021-06-16T15:23:09.802454Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 651954 characters\n"
     ]
    }
   ],
   "source": [
    "raw = raw_data.load_raw(\"../data/names.txt\")\n",
    "text = raw_data.join_raw(raw)\n",
    "vocab = vectorize.extract_vocab(text)\n",
    "\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adray Lasbard                                                                                       \\nAlbel Nox                                                                                           \\nCliff Fittir                                                                                      '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:09.806036Z",
     "iopub.status.busy": "2021-06-16T15:23:09.805502Z",
     "iopub.status.idle": "2021-06-16T15:23:09.807205Z",
     "shell.execute_reply": "2021-06-16T15:23:09.807599Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adray Lasbard                                                                                       \n",
      "Albel Nox                                                                                           \n",
      "Cliff Fittir                                    \n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:09.819578Z",
     "iopub.status.busy": "2021-06-16T15:23:09.819053Z",
     "iopub.status.idle": "2021-06-16T15:23:09.820995Z",
     "shell.execute_reply": "2021-06-16T15:23:09.821315Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = vectorize.extract_vocab(text)\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Process the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Vectorize the text\n",
    "\n",
    "Before training, you need to convert the strings to a numerical representation. \n",
    "\n",
    "The `preprocessing.StringLookup` layer can convert each character into a numeric ID. It just needs the text to be split into tokens first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.106489Z",
     "iopub.status.busy": "2021-06-16T15:23:11.105807Z",
     "iopub.status.idle": "2021-06-16T15:23:11.384611Z",
     "shell.execute_reply": "2021-06-16T15:23:11.383945Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = vectorize.unicode_split(example_texts)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorator = vectorize.Vectorator(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmX_jbgQqfOi"
   },
   "source": [
    "It converts form tokens to character IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.403321Z",
     "iopub.status.busy": "2021-06-16T15:23:11.402650Z",
     "iopub.status.idle": "2021-06-16T15:23:11.406461Z",
     "shell.execute_reply": "2021-06-16T15:23:11.406788Z"
    },
    "id": "WLv5Q_2TC2pc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 46, 47, 48, 49, 50, 51], [68, 69, 70]]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = vectorator.ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "Since the goal of this tutorial is to generate text, it will also be important to invert this representation and recover human-readable strings from it. For this you can use `preprocessing.StringLookup(..., invert=True)`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uenivzwqsDhp"
   },
   "source": [
    "Note: Here instead of passing the original vocabulary generated with `sorted(set(text))` use the `get_vocabulary()` method of the `preprocessing.StringLookup` layer so that the `[UNK]` tokens is set the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqTDDxS-s-H8"
   },
   "source": [
    "This layer recovers the characters from the vectors of IDs, and returns them as a `tf.RaggedTensor` of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.418750Z",
     "iopub.status.busy": "2021-06-16T15:23:11.418100Z",
     "iopub.status.idle": "2021-06-16T15:23:11.421360Z",
     "shell.execute_reply": "2021-06-16T15:23:11.421695Z"
    },
    "id": "c2GCh0ySD44s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = vectorator.chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "### The prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wssHQ1oGymwe"
   },
   "source": [
    "Given a character, or a sequence of characters, what is the most probable next character? This is the task you're training the model to perform. The input to the model will be a sequence of characters, and you train the model to predict the output—the following character at each time step.\n",
    "\n",
    "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Create training examples and targets\n",
    "\n",
    "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
    "\n",
    "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
    "\n",
    "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
    "\n",
    "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = vectorize.DataSet(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "The `batch` method lets you easily convert these individual characters to sequences of the desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "For training you'll need a dataset of `(input, label)` pairs. Where `input` and \n",
    "`label` are sequences. At each time step the input is the current character and the label is the next character. \n",
    "\n",
    "Here's a function that takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:11.963007Z",
     "iopub.status.busy": "2021-06-16T15:23:11.962343Z",
     "iopub.status.idle": "2021-06-16T15:23:11.965433Z",
     "shell.execute_reply": "2021-06-16T15:23:11.964994Z"
    },
    "id": "WxbDTJTw5u_P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize.split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Create training batches\n",
    "\n",
    "You used `tf.data` to split the text into manageable sequences. But before feeding this data into the model, you need to shuffle the data and pack it into batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Build The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "This section defines the model as a `keras.Model` subclass (For details see [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
    "\n",
    "This model has three layers:\n",
    "\n",
    "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map each character-ID to a vector with `embedding_dim` dimensions;\n",
    "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n",
    "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:12.044401Z",
     "iopub.status.busy": "2021-06-16T15:23:12.043777Z",
     "iopub.status.idle": "2021-06-16T15:23:12.045488Z",
     "shell.execute_reply": "2021-06-16T15:23:12.045828Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "# vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:12.057187Z",
     "iopub.status.busy": "2021-06-16T15:23:12.056553Z",
     "iopub.status.idle": "2021-06-16T15:23:12.066178Z",
     "shell.execute_reply": "2021-06-16T15:23:12.065730Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "model = seq_model.SeqModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=ds.vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkA5upJIJ7W7"
   },
   "source": [
    "For each character the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character:\n",
    "\n",
    "![A drawing of the data passing through the model](images/text_generation_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKbfm04amhXk"
   },
   "source": [
    "Note: For training you could use a `keras.Sequential` model here. To  generate text later you'll need to manage the RNN's internal state. It's simpler to include the state input and output options upfront, than it is to rearrange the model architecture later. For more details see the [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## Try the model\n",
    "\n",
    "Now run the model to see that it behaves as expected.\n",
    "\n",
    "First check the shape of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:12.070191Z",
     "iopub.status.busy": "2021-06-16T15:23:12.069612Z",
     "iopub.status.idle": "2021-06-16T15:23:14.644916Z",
     "shell.execute_reply": "2021-06-16T15:23:14.645260Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 79) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in ds.dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6NzLBi4VM4o"
   },
   "source": [
    "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.649909Z",
     "iopub.status.busy": "2021-06-16T15:23:14.649350Z",
     "iopub.status.idle": "2021-06-16T15:23:14.652204Z",
     "shell.execute_reply": "2021-06-16T15:23:14.652543Z"
    },
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  20224     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  80975     \n",
      "=================================================================\n",
      "Total params: 4,039,503\n",
      "Trainable params: 4,039,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "To get actual predictions from the model you need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
    "\n",
    "Note: It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.\n",
    "\n",
    "Try it for the first example in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.656316Z",
     "iopub.status.busy": "2021-06-16T15:23:14.655704Z",
     "iopub.status.idle": "2021-06-16T15:23:14.658423Z",
     "shell.execute_reply": "2021-06-16T15:23:14.658814Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "This gives us, at each timestep, a prediction of the next character index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.662823Z",
     "iopub.status.busy": "2021-06-16T15:23:14.662207Z",
     "iopub.status.idle": "2021-06-16T15:23:14.664468Z",
     "shell.execute_reply": "2021-06-16T15:23:14.664796Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27,  9, 27, 54, 28, 33, 43, 78, 72, 28, 14,  8, 47, 69, 62, 15, 48,\n",
       "        8, 18, 31, 33, 70, 16, 55, 67, 59, 14, 76, 22,  3, 16,  1, 68, 53,\n",
       "       78, 68, 35, 59, 61, 64, 65, 32, 77, 32, 21,  4,  8, 24, 27, 11, 41,\n",
       "       75, 25,  7, 76,  3, 10, 44, 50,  9, 45, 71, 54, 17, 77, 32,  2, 29,\n",
       "       52, 52, 74, 11,  5,  1, 30, 29, 13, 61, 46, 58, 61, 72, 42, 36,  9,\n",
       "        6, 49, 48, 52, 46, 16, 35,  2, 35, 27, 25, 10, 61, 11, 15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "Decode these to see the text predicted by this untrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.668624Z",
     "iopub.status.busy": "2021-06-16T15:23:14.668019Z",
     "iopub.status.idle": "2021-06-16T15:23:14.672269Z",
     "shell.execute_reply": "2021-06-16T15:23:14.672602Z"
    },
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " ['Great Deku Tree                                                                                     ']\n",
      "\n",
      "Next Char Predictions:\n",
      " [\"I0IjJOYīáJ6/cyr7d/?MOz8kwo6öD&8\\nxiīxQoqtuNāNC'/FI2WóG.ö&1Zf0aÓj9āN Khhí2,\\nLK5qbnqáXR0-edhb8Q QIG1q27\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", ds.text_from_ids(np.array([input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", ds.text_from_ids(np.array([sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "### Attach an optimizer, and a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "The standard `tf.keras.losses.sparse_categorical_crossentropy` loss function works in this case because it is applied across the last dimension of the predictions.\n",
    "\n",
    "Because your model returns logits, you need to set the `from_logits` flag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.676237Z",
     "iopub.status.busy": "2021-06-16T15:23:14.675670Z",
     "iopub.status.idle": "2021-06-16T15:23:14.677378Z",
     "shell.execute_reply": "2021-06-16T15:23:14.677702Z"
    },
    "id": "ZOeWdgxNFDXq"
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.681665Z",
     "iopub.status.busy": "2021-06-16T15:23:14.681125Z",
     "iopub.status.idle": "2021-06-16T15:23:14.687262Z",
     "shell.execute_reply": "2021-06-16T15:23:14.686833Z"
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 79)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         4.383516\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkvUIneTFiow"
   },
   "source": [
    "A newly initialized model shouldn't be too sure of itself, the output logits should all have similar magnitudes. To confirm this you can check that the exponential of the mean loss is approximately equal to the vocabulary size. A much higher loss means the model is sure of its wrong answers, and is badly initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.690546Z",
     "iopub.status.busy": "2021-06-16T15:23:14.690018Z",
     "iopub.status.idle": "2021-06-16T15:23:14.693545Z",
     "shell.execute_reply": "2021-06-16T15:23:14.693089Z"
    },
    "id": "MAJfS5YoFiHf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.119225"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeOXriLcymww"
   },
   "source": [
    "Configure the training procedure using the `tf.keras.Model.compile` method. Use `tf.keras.optimizers.Adam` with default arguments and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.699890Z",
     "iopub.status.busy": "2021-06-16T15:23:14.699359Z",
     "iopub.status.idle": "2021-06-16T15:23:14.704390Z",
     "shell.execute_reply": "2021-06-16T15:23:14.703935Z"
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6XBUUavgF56"
   },
   "source": [
    "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.708240Z",
     "iopub.status.busy": "2021-06-16T15:23:14.707582Z",
     "iopub.status.idle": "2021-06-16T15:23:14.709420Z",
     "shell.execute_reply": "2021-06-16T15:23:14.709740Z"
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "To keep training time reasonable, use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.712994Z",
     "iopub.status.busy": "2021-06-16T15:23:14.712456Z",
     "iopub.status.idle": "2021-06-16T15:23:14.714281Z",
     "shell.execute_reply": "2021-06-16T15:23:14.714660Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:23:14.718215Z",
     "iopub.status.busy": "2021-06-16T15:23:14.717580Z",
     "iopub.status.idle": "2021-06-16T15:25:02.747960Z",
     "shell.execute_reply": "2021-06-16T15:25:02.747311Z"
    },
    "id": "UK-hmKjYVoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 6s 37ms/step - loss: 0.5424\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 4s 37ms/step - loss: 0.3307\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 4s 37ms/step - loss: 0.2974\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 4s 37ms/step - loss: 0.3061\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2783\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2663\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2655\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2703\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2628\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2632\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2581\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2484\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2560\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.2459\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2351\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2436\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2278\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2269\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.2180\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 5s 39ms/step - loss: 0.2039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIdQ8c8NvMzV"
   },
   "source": [
    "The simplest way to generate text with this model is to run it in a loop, and keep track of the model's internal state as you execute it.\n",
    "\n",
    "![To generate text the model's output is fed back to the input](images/text_generation_sampling.png)\n",
    "\n",
    "Each time you call the model you pass in some text and an internal state. The model returns a prediction for the next character and its new state. Pass the prediction and state back in to continue generating text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "The following makes a single step prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:02.756171Z",
     "iopub.status.busy": "2021-06-16T15:25:02.755541Z",
     "iopub.status.idle": "2021-06-16T15:25:02.757358Z",
     "shell.execute_reply": "2021-06-16T15:25:02.757731Z"
    },
    "id": "iSBU1tHmlUSs"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:02.761943Z",
     "iopub.status.busy": "2021-06-16T15:25:02.761350Z",
     "iopub.status.idle": "2021-06-16T15:25:02.767592Z",
     "shell.execute_reply": "2021-06-16T15:25:02.767096Z"
    },
    "id": "fqMOuDutnOxK"
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9yDoa0G3IgQ"
   },
   "source": [
    "Run it in a loop to generate some text. Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:02.772943Z",
     "iopub.status.busy": "2021-06-16T15:25:02.772363Z",
     "iopub.status.idle": "2021-06-16T15:25:05.014954Z",
     "shell.execute_reply": "2021-06-16T15:25:05.015310Z"
    },
    "id": "ST7PSyk9t1mT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo                                                                                                      \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.804236650466919\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Romeo '])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "The easiest thing you can do to improve the results is to train it for longer (try `EPOCHS = 30`).\n",
    "\n",
    "You can also experiment with a different start string, try adding another RNN layer to improve the model's accuracy, or adjust the temperature parameter to generate more or less random predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OfbI4aULmuj"
   },
   "source": [
    "If you want the model to generate text *faster* the easiest thing you can do is batch the text generation. In the example below the model generates 5 outputs in about the same time it took to generate 1 above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:05.021167Z",
     "iopub.status.busy": "2021-06-16T15:25:05.020608Z",
     "iopub.status.idle": "2021-06-16T15:25:07.138137Z",
     "shell.execute_reply": "2021-06-16T15:25:07.138522Z"
    },
    "id": "ZkLu7Y8UCMT7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Quheny Iruniaka                                                                                      '\n",
      " b'WortG                                                                                                '\n",
      " b'Effya Ruseis Sa Tramurt                                                                              '\n",
      " b'Ranza                                                                                                '\n",
      " b'Tromp Coat                                                                                           '\n",
      " b'Yegul Bragh                                                                                          '\n",
      " b'Umer Aughterm                                                                                        '\n",
      " b'Ispo                                                                                                 '\n",
      " b'Ocarige                                                                                              '\n",
      " b'Preato Ros                                                                                           '\n",
      " b'Ashagas                                                                                              '\n",
      " b'Seroka Keatoha                                                                                       '\n",
      " b'Dr. Toaros                                                                                           '\n",
      " b'Flarr                                                                                                '\n",
      " b'Gensah                                                                                               '\n",
      " b'Hinoffurd                                                                                            '\n",
      " b'Junney                                                                                               '\n",
      " b'Kogago Roke                                                                                          '\n",
      " b'Linga                                                                                                '\n",
      " b'Zahe                                                                                                 '\n",
      " b'Xerd Toriku                                                                                          '\n",
      " b'Choccoul                                                                                             '\n",
      " b'Victoro                                                                                              '\n",
      " b'Buwnbrae                                                                                             '\n",
      " b'Nex                                                                                                  '\n",
      " b'Mions                                                                                                '], shape=(26,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.745201587677002\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"))\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlUQzwu6EXam"
   },
   "source": [
    "## Export the generator\n",
    "\n",
    "This single-step model can easily be [saved and restored](https://www.tensorflow.org/guide/saved_model), allowing you to use it anywhere a `tf.saved_model` is accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:07.142739Z",
     "iopub.status.busy": "2021-06-16T15:25:07.142196Z",
     "iopub.status.idle": "2021-06-16T15:25:13.133633Z",
     "shell.execute_reply": "2021-06-16T15:25:13.133109Z"
    },
    "id": "3Grk32H_CzsC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x00000150C6631CD0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.139970Z",
     "iopub.status.busy": "2021-06-16T15:25:13.139254Z",
     "iopub.status.idle": "2021-06-16T15:25:13.449381Z",
     "shell.execute_reply": "2021-06-16T15:25:13.449729Z"
    },
    "id": "_Z9bb_wX6Uuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:a                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## Advanced: Customized Training\n",
    "\n",
    "The above training procedure is simple, but does not give you much control.\n",
    "It uses teacher-forcing which prevents bad predictions from being fed back to the model, so the model never learns to recover from mistakes.\n",
    "\n",
    "So now that you've seen how to run the model manually next you'll implement the training loop. This gives a starting point if, for example, you want to implement _curriculum  learning_ to help stabilize the model's open-loop output.\n",
    "\n",
    "The most important part of a custom training loop is the train step function.\n",
    "\n",
    "Use `tf.GradientTape` to track the gradients. You can learn more about this approach by reading the [eager execution guide](https://www.tensorflow.org/guide/eager).\n",
    "\n",
    "The basic procedure is:\n",
    "\n",
    "1. Execute the model and calculate the loss under a `tf.GradientTape`.\n",
    "2. Calculate the updates and apply them to the model using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.455005Z",
     "iopub.status.busy": "2021-06-16T15:25:13.454208Z",
     "iopub.status.idle": "2021-06-16T15:25:13.456512Z",
     "shell.execute_reply": "2021-06-16T15:25:13.456079Z"
    },
    "id": "x0pZ101hjwW0"
   },
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Oc-eJALcK8B"
   },
   "source": [
    "The above implementation of the `train_step` method follows [Keras' `train_step` conventions](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). This is optional, but it allows you to change the behavior of the train step and still use keras' `Model.compile` and `Model.fit` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.461477Z",
     "iopub.status.busy": "2021-06-16T15:25:13.460619Z",
     "iopub.status.idle": "2021-06-16T15:25:13.466301Z",
     "shell.execute_reply": "2021-06-16T15:25:13.466645Z"
    },
    "id": "XKyWiZ_Lj7w5"
   },
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.472720Z",
     "iopub.status.busy": "2021-06-16T15:25:13.471525Z",
     "iopub.status.idle": "2021-06-16T15:25:13.475448Z",
     "shell.execute_reply": "2021-06-16T15:25:13.475016Z"
    },
    "id": "U817KUm7knlm"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:13.479322Z",
     "iopub.status.busy": "2021-06-16T15:25:13.478412Z",
     "iopub.status.idle": "2021-06-16T15:25:20.421343Z",
     "shell.execute_reply": "2021-06-16T15:25:20.420880Z"
    },
    "id": "o694aoBPnEi9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 6s 40ms/step - loss: 0.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x152f27d7cd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8nAtKHVoInR"
   },
   "source": [
    "Or if you need more control, you can write your own complete custom training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:25:20.428870Z",
     "iopub.status.busy": "2021-06-16T15:25:20.428217Z",
     "iopub.status.idle": "2021-06-16T15:26:14.285123Z",
     "shell.execute_reply": "2021-06-16T15:26:14.285463Z"
    },
    "id": "d4tSNwymzf-q",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.3546\n",
      "Epoch 1 Batch 50 Loss 0.3626\n",
      "\n",
      "Epoch 1 Loss: 0.3432\n",
      "Time taken for 1 epoch 4.82 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 2 Batch 0 Loss 0.3352\n",
      "Epoch 2 Batch 50 Loss 0.3490\n",
      "\n",
      "Epoch 2 Loss: 0.2995\n",
      "Time taken for 1 epoch 4.30 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 3 Batch 0 Loss 0.3017\n",
      "Epoch 3 Batch 50 Loss 0.3941\n",
      "\n",
      "Epoch 3 Loss: 0.3002\n",
      "Time taken for 1 epoch 4.26 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 4 Batch 0 Loss 0.3002\n",
      "Epoch 4 Batch 50 Loss 0.2861\n",
      "\n",
      "Epoch 4 Loss: 0.2766\n",
      "Time taken for 1 epoch 4.24 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 5 Batch 0 Loss 0.2230\n",
      "Epoch 5 Batch 50 Loss 0.2779\n",
      "\n",
      "Epoch 5 Loss: 0.2808\n",
      "Time taken for 1 epoch 4.45 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 6 Batch 0 Loss 0.2855\n",
      "Epoch 6 Batch 50 Loss 0.2377\n",
      "\n",
      "Epoch 6 Loss: 0.2703\n",
      "Time taken for 1 epoch 4.28 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 7 Batch 0 Loss 0.2802\n",
      "Epoch 7 Batch 50 Loss 0.2465\n",
      "\n",
      "Epoch 7 Loss: 0.2663\n",
      "Time taken for 1 epoch 4.32 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 8 Batch 0 Loss 0.2573\n",
      "Epoch 8 Batch 50 Loss 0.2546\n",
      "\n",
      "Epoch 8 Loss: 0.2547\n",
      "Time taken for 1 epoch 4.30 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 9 Batch 0 Loss 0.2492\n",
      "Epoch 9 Batch 50 Loss 0.2616\n",
      "\n",
      "Epoch 9 Loss: 0.2607\n",
      "Time taken for 1 epoch 4.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 10 Batch 0 Loss 0.2497\n",
      "Epoch 10 Batch 50 Loss 0.2188\n",
      "\n",
      "Epoch 10 Loss: 0.2694\n",
      "Time taken for 1 epoch 4.54 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 11 Batch 0 Loss 0.2704\n",
      "Epoch 11 Batch 50 Loss 0.2706\n",
      "\n",
      "Epoch 11 Loss: 0.2583\n",
      "Time taken for 1 epoch 4.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 12 Batch 0 Loss 0.2243\n",
      "Epoch 12 Batch 50 Loss 0.2167\n",
      "\n",
      "Epoch 12 Loss: 0.2534\n",
      "Time taken for 1 epoch 4.36 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 13 Batch 0 Loss 0.2475\n",
      "Epoch 13 Batch 50 Loss 0.2611\n",
      "\n",
      "Epoch 13 Loss: 0.2507\n",
      "Time taken for 1 epoch 4.36 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 14 Batch 0 Loss 0.2376\n",
      "Epoch 14 Batch 50 Loss 0.2294\n",
      "\n",
      "Epoch 14 Loss: 0.2410\n",
      "Time taken for 1 epoch 4.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 15 Batch 0 Loss 0.2262\n",
      "Epoch 15 Batch 50 Loss 0.2618\n",
      "\n",
      "Epoch 15 Loss: 0.2391\n",
      "Time taken for 1 epoch 4.57 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 16 Batch 0 Loss 0.2339\n",
      "Epoch 16 Batch 50 Loss 0.2290\n",
      "\n",
      "Epoch 16 Loss: 0.2314\n",
      "Time taken for 1 epoch 4.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 17 Batch 0 Loss 0.2224\n",
      "Epoch 17 Batch 50 Loss 0.2647\n",
      "\n",
      "Epoch 17 Loss: 0.2437\n",
      "Time taken for 1 epoch 4.49 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 18 Batch 0 Loss 0.2130\n",
      "Epoch 18 Batch 50 Loss 0.2029\n",
      "\n",
      "Epoch 18 Loss: 0.2164\n",
      "Time taken for 1 epoch 4.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 19 Batch 0 Loss 0.2031\n",
      "Epoch 19 Batch 50 Loss 0.2427\n",
      "\n",
      "Epoch 19 Loss: 0.2365\n",
      "Time taken for 1 epoch 4.37 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 20 Batch 0 Loss 0.2154\n",
      "Epoch 20 Batch 50 Loss 0.2006\n",
      "\n",
      "Epoch 20 Loss: 0.2052\n",
      "Time taken for 1 epoch 4.55 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 21 Batch 0 Loss 0.1839\n",
      "Epoch 21 Batch 50 Loss 0.1800\n",
      "\n",
      "Epoch 21 Loss: 0.1976\n",
      "Time taken for 1 epoch 4.43 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 22 Batch 0 Loss 0.1727\n",
      "Epoch 22 Batch 50 Loss 0.2294\n",
      "\n",
      "Epoch 22 Loss: 0.1857\n",
      "Time taken for 1 epoch 4.39 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 23 Batch 0 Loss 0.1673\n",
      "Epoch 23 Batch 50 Loss 0.2207\n",
      "\n",
      "Epoch 23 Loss: 0.1909\n",
      "Time taken for 1 epoch 4.38 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 24 Batch 0 Loss 0.1756\n",
      "Epoch 24 Batch 50 Loss 0.1643\n",
      "\n",
      "Epoch 24 Loss: 0.1656\n",
      "Time taken for 1 epoch 4.45 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 25 Batch 0 Loss 0.1572\n",
      "Epoch 25 Batch 50 Loss 0.1589\n",
      "\n",
      "Epoch 25 Loss: 0.1557\n",
      "Time taken for 1 epoch 4.64 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 26 Batch 0 Loss 0.2233\n",
      "Epoch 26 Batch 50 Loss 0.1606\n",
      "\n",
      "Epoch 26 Loss: 0.1619\n",
      "Time taken for 1 epoch 4.40 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 27 Batch 0 Loss 0.1305\n",
      "Epoch 27 Batch 50 Loss 0.1178\n",
      "\n",
      "Epoch 27 Loss: 0.1494\n",
      "Time taken for 1 epoch 4.49 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 28 Batch 0 Loss 0.1330\n",
      "Epoch 28 Batch 50 Loss 0.1293\n",
      "\n",
      "Epoch 28 Loss: 0.1338\n",
      "Time taken for 1 epoch 4.46 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 29 Batch 0 Loss 0.1336\n",
      "Epoch 29 Batch 50 Loss 0.1156\n",
      "\n",
      "Epoch 29 Loss: 0.1247\n",
      "Time taken for 1 epoch 4.46 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 30 Batch 0 Loss 0.1097\n",
      "Epoch 30 Batch 50 Loss 0.1083\n",
      "\n",
      "Epoch 30 Loss: 0.1137\n",
      "Time taken for 1 epoch 4.68 sec\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "mean = tf.metrics.Mean()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    mean.reset_states()\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = model.train_step([inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "\n",
    "        if batch_n % 50 == 0:\n",
    "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
    "            print(template)\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print()\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
    "    print(\"_\"*80)\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Quinfair                                 '\n",
      " b'Wanth                                    '\n",
      " b'Ellia                                    '\n",
      " b'Runa                                     '\n",
      " b'Torby                                    '\n",
      " b'Yug Parinz                               '\n",
      " b'Unsearie                                 '\n",
      " b'Izri                                     '\n",
      " b'Olia Jelfa                               '\n",
      " b'Pokielta                                 '\n",
      " b'Anne                                     '\n",
      " b'Sah Larabold                             '\n",
      " b'Degame Lukis Caelum                      '\n",
      " b'Futo                                     '\n",
      " b'Griff                                    '\n",
      " b'Hash                                     '\n",
      " b'Jyon Drimam                              '\n",
      " b\"Ko'shoho                                 \"\n",
      " b'Liqus                                    '\n",
      " b'Zolb Broh                                '\n",
      " b'Xansurabueq                              '\n",
      " b'Choco                                    '\n",
      " b'Vilba                                    '\n",
      " b'Blark                                    '\n",
      " b'Nadlichter Yumesch                       '\n",
      " b'Mivison                                  '], shape=(26,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.07636833190917969\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"))\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(40):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quan', 'Wycch', 'Exfis Nohder', 'Rinaha', 'Tyrit', 'Yughin', 'Uhniriok Oad Koropa', 'Igona Shimis', 'Ovagri', 'Poppi', 'A-Tappa', 'Savine', 'Dumah Jaabu do', 'Faketh', 'GrannyWa', 'Halzand', 'Jowanne', \"Ke'n jah\", 'Leviar Luki', 'Zhani', 'Xundler', 'Cleus Fate', 'Viwela', 'Bgend Lacheery', 'Noraha', 'Masper'] \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.08176589012145996\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(list(\"QWERTYUIOPASDFGHJKLZXCVBNM\"))\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(40):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "result = [\" \".join([a.strip() for a in name.decode(\"utf-8\").split() if len(a)]) for name in result.numpy()]\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(stem=\"\", n=1):\n",
    "    names = []\n",
    "    for _ in range(n):\n",
    "        states = None\n",
    "        next_char = [stem + ch for ch in \"QWERTYUIOPASDFGHJKLZXCVBNM\"]\n",
    "        next_char = tf.constant(next_char)\n",
    "        result = [next_char]\n",
    "\n",
    "        for n in range(40):\n",
    "          next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "          result.append(next_char)\n",
    "\n",
    "        result = tf.strings.join(result)\n",
    "        names += [\" \".join([a.strip() for a in name.decode(\"utf-8\").split() if len(a)]) for name in result.numpy()]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qunan',\n",
       " 'Wattitahf',\n",
       " 'Eddrate',\n",
       " 'Rowamal',\n",
       " 'Tepla Totorien',\n",
       " 'Yeski',\n",
       " 'Unhweaner',\n",
       " 'Ictina',\n",
       " 'Old Mah',\n",
       " 'Puncit',\n",
       " 'Azer',\n",
       " 'Soutasner',\n",
       " 'Dr. Tradsei',\n",
       " 'Frana',\n",
       " 'Gaurthellerid',\n",
       " 'Heschov',\n",
       " 'Jecion',\n",
       " 'Kutoka',\n",
       " \"Letri's Bar Les Soum\",\n",
       " 'Zekkrim',\n",
       " 'Xhia Vectrima',\n",
       " 'Chloh',\n",
       " 'Vannion',\n",
       " 'Bakiba',\n",
       " 'Nubrokuix',\n",
       " 'Mikkue',\n",
       " 'Quiltous of Ciant Fa',\n",
       " 'Waltzon',\n",
       " 'Enneus',\n",
       " 'Rowdelpus',\n",
       " 'Theit',\n",
       " 'Yogenkt',\n",
       " 'Ukaagale',\n",
       " 'Illah',\n",
       " 'Oad',\n",
       " 'Phoco',\n",
       " 'Anigagu',\n",
       " 'Stahny',\n",
       " 'Derolicite',\n",
       " 'Fildie Drien',\n",
       " 'Gairo',\n",
       " 'Hathia Leffall',\n",
       " 'Jew-O-Senne',\n",
       " 'Katara Yoto',\n",
       " 'Lithimo',\n",
       " 'Zusanaru',\n",
       " 'Xard-Chondian',\n",
       " 'Cain Leugh',\n",
       " 'Vaevan chep',\n",
       " 'Bicha',\n",
       " 'Nalta',\n",
       " 'Modori',\n",
       " 'Quiek trick',\n",
       " 'Westar',\n",
       " 'Eimiso Sabronaulur',\n",
       " \"Raine's Lother\",\n",
       " 'Thegnagl',\n",
       " 'Yukh',\n",
       " 'Utitona',\n",
       " 'Ilake Selkerkiee',\n",
       " 'Orolia Arbirchina',\n",
       " 'Partos',\n",
       " 'Antconburet de Houshairle',\n",
       " 'Sairomaha',\n",
       " 'Dinkle',\n",
       " 'Fostorr Yosser',\n",
       " 'Guiri ofise Thie',\n",
       " 'Harthon',\n",
       " 'Jopeen',\n",
       " \"Ko'shomama\",\n",
       " 'Linduv',\n",
       " 'Zerlance',\n",
       " 'Xon Ba Luiro',\n",
       " 'Chirolo',\n",
       " 'Vally',\n",
       " 'Beiz Kiam',\n",
       " 'Nierrales',\n",
       " 'Merdo',\n",
       " 'Quine Arvild',\n",
       " 'Whphattahn and Sornerp',\n",
       " 'Eschit',\n",
       " 'Rupia Carouli',\n",
       " 'Tadamuk',\n",
       " 'Yu-Rupu',\n",
       " 'Uthi',\n",
       " 'Ior',\n",
       " 'Occra',\n",
       " 'Patherua',\n",
       " 'Allye Lypbl Ba',\n",
       " 'Sior',\n",
       " 'Derekk',\n",
       " 'Fy Prah Frach',\n",
       " 'Gelo',\n",
       " 'Henrac',\n",
       " 'Josama A-Sugay',\n",
       " 'Klous Rornbea',\n",
       " 'Luschpottas',\n",
       " 'Zana ute',\n",
       " 'XXe Canetiro',\n",
       " 'Carbelle',\n",
       " 'Viroma',\n",
       " 'Bogton Srocksaant',\n",
       " 'Nele',\n",
       " 'Moka',\n",
       " 'Qufeidout de Creciaurut',\n",
       " 'Wettbrantu',\n",
       " 'Eymer Scorisah',\n",
       " 'Rachords',\n",
       " 'Tentour',\n",
       " 'Ylari Roveine',\n",
       " 'Ulian',\n",
       " 'Igehtongeeshe',\n",
       " 'Otone',\n",
       " 'Pufple',\n",
       " 'Astzreber',\n",
       " 'Saghriet',\n",
       " 'Dutoc',\n",
       " 'Fextharst',\n",
       " 'Ghith Fibis Oatier',\n",
       " 'Hollio Troperr',\n",
       " 'Jun-Luxic',\n",
       " 'Kaith Hatyha',\n",
       " 'Lolegito',\n",
       " 'Zatzroba',\n",
       " 'Xakan',\n",
       " 'Charlond',\n",
       " 'Vasacortin',\n",
       " 'Burouk',\n",
       " 'Noryatier',\n",
       " 'Menceston',\n",
       " 'Quheentoepe',\n",
       " 'Wivestorf',\n",
       " 'Edray Jarandsonn',\n",
       " 'Rona',\n",
       " 'Tald Cheen',\n",
       " 'Yues',\n",
       " 'Unnelli',\n",
       " 'Iverora Kean',\n",
       " 'Ougeringerg Warron',\n",
       " 'Pershyus Dathersion',\n",
       " 'Ahoros',\n",
       " 'Shortor Machari-',\n",
       " 'Decku',\n",
       " 'Fyoromos',\n",
       " 'Gilmamesh',\n",
       " 'Hallmyn',\n",
       " 'Jelline',\n",
       " 'King of Lucisua',\n",
       " 'Lavible',\n",
       " 'Zorbbragi Titah',\n",
       " 'Xagner',\n",
       " 'Cid',\n",
       " 'Valera',\n",
       " 'Boz Sothard',\n",
       " 'Nazan',\n",
       " 'Moshtome',\n",
       " 'Quittuse perrille',\n",
       " 'Womp Vinia',\n",
       " 'Eluha',\n",
       " 'Rona',\n",
       " 'Teyue',\n",
       " 'Yuk hinttell',\n",
       " 'Uvei',\n",
       " \"I'lmavi Tirius\",\n",
       " 'Omoglofer',\n",
       " 'Pussequime',\n",
       " 'Anev Deablin',\n",
       " 'Spiraty',\n",
       " 'Deah Bahren',\n",
       " 'Floor',\n",
       " 'Ginor',\n",
       " 'Holes',\n",
       " 'Jaia',\n",
       " 'Kamena Teruhgia',\n",
       " 'Leyza',\n",
       " 'Zubelthei',\n",
       " 'XXmisse',\n",
       " 'Cambertia',\n",
       " 'Venatiria',\n",
       " 'Busherus Adothars',\n",
       " 'Nana',\n",
       " 'Maggick',\n",
       " \"Qu'lletharnuch\",\n",
       " 'Weffy',\n",
       " 'Elina Ulmisch',\n",
       " 'Rigrosfast',\n",
       " 'Trakus',\n",
       " 'Yarafaur',\n",
       " 'Ulia',\n",
       " 'Irchuld Macreiorgei',\n",
       " 'Oran',\n",
       " 'Pulmic',\n",
       " 'Albhon andord',\n",
       " 'Suyriuk',\n",
       " 'Dantront mikh',\n",
       " 'Froro',\n",
       " 'Garnett Crossmonn',\n",
       " 'Hildamds',\n",
       " \"Janato '\",\n",
       " 'KanYouz',\n",
       " 'Lata Bahuth',\n",
       " 'Zubert Duthreadu',\n",
       " 'Xonhealt',\n",
       " 'Cravellerts.',\n",
       " 'Vollure',\n",
       " 'Buyomor',\n",
       " 'Nyrobad',\n",
       " 'Mol',\n",
       " 'Quine qus de Tuenaril',\n",
       " 'Winitrun',\n",
       " 'Erik',\n",
       " 'Ridath',\n",
       " 'Tinal Fantusy',\n",
       " 'Yupila',\n",
       " 'Unili',\n",
       " 'I-Spera',\n",
       " 'Oulval qua Brand chma',\n",
       " 'Pray',\n",
       " 'Aphaserom',\n",
       " 'Sharlemogg',\n",
       " 'Daruous',\n",
       " 'Fraid',\n",
       " \"G'lihama Thini\",\n",
       " 'Hectti',\n",
       " 'Jaelleresseim',\n",
       " 'Kalania Rash',\n",
       " 'Lahsan Drontsan',\n",
       " 'Zerbuka',\n",
       " 'Xantue',\n",
       " 'Cass Gorson',\n",
       " 'VenBuldia',\n",
       " 'Brilgring da Zamaille',\n",
       " 'Naiten Smamhos',\n",
       " 'Mifilo',\n",
       " 'Queen qus Alluraar',\n",
       " 'Wadonius',\n",
       " 'Ephta',\n",
       " 'Robers',\n",
       " 'Treadort',\n",
       " 'Yudahu 7 Thehu',\n",
       " 'Uzezio',\n",
       " 'Inki Kanza',\n",
       " 'Olas',\n",
       " 'Puenarick',\n",
       " 'Altanica',\n",
       " 'Sirubelvwang der Devearon',\n",
       " 'Darwanne Queen',\n",
       " 'Flack',\n",
       " 'Glatzhmarh',\n",
       " 'Harge',\n",
       " 'Jossira Mechtein',\n",
       " 'Kakave',\n",
       " 'Lonyx',\n",
       " 'Zoo',\n",
       " \"Xush's quie\",\n",
       " 'Corita Chaulton',\n",
       " 'Vavan',\n",
       " 'Bornaisur',\n",
       " 'Nello',\n",
       " 'Marto']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joby of Que perelle Feemirot/',\n",
       " 'Joby of Warronos Orchors',\n",
       " 'Joby of Eltheim',\n",
       " 'Joby of Rundos',\n",
       " 'Joby of Tinne',\n",
       " 'Joby of Yuyme',\n",
       " 'Joby of Uldharm',\n",
       " 'Joby of Iughmind',\n",
       " 'Joby of Order',\n",
       " 'Joby of Phiden',\n",
       " 'Joby of Azentom',\n",
       " 'Joby of Selma',\n",
       " 'Joby of Deagen',\n",
       " 'Joby of Farremard',\n",
       " 'Joby of Gurdan',\n",
       " 'Joby of Heni of',\n",
       " 'Joby of Jeven',\n",
       " 'Joby of Krand',\n",
       " 'Joby of Lewmaldr',\n",
       " 'Joby of Zukeny Selio',\n",
       " 'Joby of XII',\n",
       " 'Joby of Chovencel',\n",
       " 'Joby of Vex',\n",
       " 'Joby of Beemburd',\n",
       " 'Joby of N.',\n",
       " 'Joby of Miss',\n",
       " 'Joby of Queen',\n",
       " 'Joby of Wink',\n",
       " 'Joby of Elman',\n",
       " 'Joby of RedUg',\n",
       " 'Joby of Ter',\n",
       " 'Joby of Yenne',\n",
       " 'Joby of Unnerd',\n",
       " 'Joby of Ihmovield',\n",
       " 'Joby of Oandere d',\n",
       " 'Joby of Phigeshon',\n",
       " 'Joby of Aunchtion',\n",
       " 'Joby of Scima',\n",
       " 'Joby of Delef',\n",
       " 'Joby of Furlemerm',\n",
       " 'Joby of Gyrld',\n",
       " 'Joby of Heurion',\n",
       " 'Joby of Jesherk',\n",
       " 'Joby of Keep Sal Eroda',\n",
       " 'Joby of Leshaille',\n",
       " 'Joby of Zliepos',\n",
       " 'Joby of XII',\n",
       " 'Joby of Crespann',\n",
       " 'Joby of Vandredde',\n",
       " 'Joby of Bahmell',\n",
       " 'Joby of Neh',\n",
       " 'Joby of Mexke',\n",
       " 'Joby of Qua Ne',\n",
       " 'Joby of Walghor',\n",
       " 'Joby of Eahse',\n",
       " 'Joby of Run',\n",
       " 'Joby of Timan',\n",
       " 'Joby of Yoshas',\n",
       " 'Joby of Ulmer of Lageer',\n",
       " 'Joby of Indielbert',\n",
       " 'Joby of Ommen',\n",
       " 'Joby of Pyrlen',\n",
       " 'Joby of Asmell',\n",
       " 'Joby of Shentast',\n",
       " 'Joby of Derna',\n",
       " 'Joby of Fibh',\n",
       " 'Joby of Gurgame',\n",
       " 'Joby of Huguh',\n",
       " 'Joby of Jibe',\n",
       " 'Joby of Kees',\n",
       " 'Joby of Lenit',\n",
       " 'Joby of Zerder Shentros',\n",
       " 'Joby of XIII',\n",
       " 'Joby of Chaid',\n",
       " 'Joby of VIII',\n",
       " 'Joby of Beverd',\n",
       " 'Joby of Noh',\n",
       " 'Joby of Mothers',\n",
       " 'Joby of Queen',\n",
       " 'Joby of Werwa',\n",
       " 'Joby of Erden',\n",
       " 'Joby of Rasi',\n",
       " 'Joby of Thay',\n",
       " 'Joby of Yube',\n",
       " 'Joby of Ulmyri',\n",
       " 'Joby of IIdei',\n",
       " 'Joby of Obent',\n",
       " 'Joby of Prinf',\n",
       " 'Joby of Alehand',\n",
       " 'Joby of Sneuma',\n",
       " 'Joby of Drishter',\n",
       " 'Joby of Fesmer',\n",
       " 'Joby of Glander',\n",
       " 'Joby of Hyrdel',\n",
       " 'Joby of Jeen',\n",
       " 'Joby of Kenger',\n",
       " 'Joby of Leveille',\n",
       " 'Joby of Zeeq',\n",
       " 'Joby of XII',\n",
       " 'Joby of Chepet',\n",
       " 'Joby of Verricksans',\n",
       " 'Joby of Burke',\n",
       " 'Joby of Nanas',\n",
       " 'Joby of Maggee',\n",
       " 'Joby of Qoen',\n",
       " 'Joby of Waltzser',\n",
       " 'Joby of Erdger',\n",
       " 'Joby of Rhischang',\n",
       " 'Joby of Triight',\n",
       " 'Joby of Yetgi',\n",
       " 'Joby of Urnh ald Mighos',\n",
       " 'Joby of II',\n",
       " 'Joby of Oveglederd',\n",
       " 'Joby of Phlimeth',\n",
       " 'Joby of Aliget',\n",
       " 'Joby of Serdwest',\n",
       " 'Joby of Deege',\n",
       " 'Joby of Fairg of Fornecia',\n",
       " 'Joby of Geat',\n",
       " 'Joby of Heldaen',\n",
       " 'Joby of Jasen',\n",
       " 'Joby of Kestira',\n",
       " 'Joby of Leimer',\n",
       " 'Joby of Zeag',\n",
       " 'Joby of XVIII',\n",
       " 'Joby of Cerdemord',\n",
       " 'Joby of Vyelme',\n",
       " 'Joby of Blyffi',\n",
       " 'Joby of Numith',\n",
       " 'Joby of Marden unchers',\n",
       " 'Joby of Queen',\n",
       " 'Joby of Wendeyarde Rosea',\n",
       " 'Joby of Embhoro',\n",
       " 'Joby of Randes',\n",
       " 'Joby of Trostem',\n",
       " 'Joby of Yohkih',\n",
       " 'Joby of Ulder',\n",
       " 'Joby of Irmhie',\n",
       " 'Joby of Ordol',\n",
       " 'Joby of Pepiti',\n",
       " 'Joby of Adinogh',\n",
       " 'Joby of Sellearth',\n",
       " 'Joby of Demel',\n",
       " 'Joby of Fyrres',\n",
       " 'Joby of Geurmon',\n",
       " 'Joby of Herkel',\n",
       " 'Joby of Jeedem',\n",
       " 'Joby of Keepere',\n",
       " 'Joby of Lesher',\n",
       " 'Joby of Zekk',\n",
       " 'Joby of XIgher',\n",
       " 'Joby of Coegsmam',\n",
       " 'Joby of Ventions',\n",
       " 'Joby of Brosherl',\n",
       " 'Joby of Naiden',\n",
       " 'Joby of Minas',\n",
       " 'Joby of Qeone',\n",
       " 'Joby of Wrishof',\n",
       " 'Joby of Ernect',\n",
       " 'Joby of Rennasch',\n",
       " 'Joby of Tiengo',\n",
       " 'Joby of Yurmel',\n",
       " 'Joby of Uledors',\n",
       " 'Joby of Izuner',\n",
       " 'Joby of Omby',\n",
       " 'Joby of Phennes',\n",
       " 'Joby of Ambilor',\n",
       " 'Joby of Sterns de Thigocon',\n",
       " 'Joby of D. Genne',\n",
       " 'Joby of Fights',\n",
       " 'Joby of Gevell',\n",
       " 'Joby of Herdfa Gurro',\n",
       " 'Joby of Jeann',\n",
       " 'Joby of Kent',\n",
       " 'Joby of Lerne d Ouckiar',\n",
       " 'Joby of Zurlz',\n",
       " 'Joby of Xeldheigate',\n",
       " 'Joby of Caveipy',\n",
       " 'Joby of Vordeine Shanacte',\n",
       " 'Joby of Beal',\n",
       " 'Joby of Nahpen',\n",
       " 'Joby of Moghe',\n",
       " 'Joby of Qepen',\n",
       " 'Joby of Warre',\n",
       " 'Joby of Epherda',\n",
       " 'Joby of Reck',\n",
       " 'Joby of Tun',\n",
       " 'Joby of Yeldh',\n",
       " 'Joby of Unde d Foner',\n",
       " 'Joby of Ihkhma',\n",
       " 'Joby of Obenar',\n",
       " 'Joby of Pannemis',\n",
       " 'Joby of Aldengod',\n",
       " 'Joby of Soigemond',\n",
       " 'Joby of Dinggoloh',\n",
       " 'Joby of Faireime',\n",
       " 'Joby of Ger',\n",
       " 'Joby of Henson',\n",
       " 'Joby of Jeonge',\n",
       " 'Joby of Keng',\n",
       " 'Joby of Lender',\n",
       " 'Joby of Zendeer',\n",
       " 'Joby of XIII',\n",
       " 'Joby of Cormett',\n",
       " 'Joby of Vemhounedis',\n",
       " 'Joby of Belbh',\n",
       " 'Joby of Noxser',\n",
       " 'Joby of Mexe',\n",
       " 'Joby of Qees',\n",
       " 'Joby of Welme',\n",
       " 'Joby of Eldhey',\n",
       " 'Joby of Ryfm',\n",
       " 'Joby of Trine',\n",
       " 'Joby of Yrine',\n",
       " 'Joby of Uther',\n",
       " 'Joby of Imimued',\n",
       " 'Joby of Ordynger',\n",
       " 'Joby of Phimas',\n",
       " 'Joby of Aullerlend V',\n",
       " 'Joby of Sern',\n",
       " 'Joby of Dim',\n",
       " 'Joby of Fyeh',\n",
       " 'Joby of Gaubobrean',\n",
       " 'Joby of Herlegnei',\n",
       " 'Joby of Janne',\n",
       " 'Joby of Kean',\n",
       " 'Joby of Lewhnind',\n",
       " 'Joby of Zesket',\n",
       " 'Joby of XIII',\n",
       " 'Joby of Chevard',\n",
       " 'Joby of Virikle',\n",
       " 'Joby of Beldeant',\n",
       " 'Joby of Nox',\n",
       " 'Joby of Maseruyma',\n",
       " 'Joby of Qeeper',\n",
       " 'Joby of Wyrg',\n",
       " 'Joby of Esthermiph',\n",
       " 'Joby of Rane',\n",
       " 'Joby of Tuinor',\n",
       " 'Joby of Ylour',\n",
       " 'Joby of Ulmer',\n",
       " 'Joby of IXII',\n",
       " 'Joby of Ork',\n",
       " 'Joby of Pbrifiil',\n",
       " 'Joby of Aveler',\n",
       " 'Joby of Surh',\n",
       " 'Joby of Derrendy',\n",
       " 'Joby of Feire',\n",
       " 'Joby of Gead',\n",
       " 'Joby of Hoshen and Thind',\n",
       " 'Joby of Jegge',\n",
       " 'Joby of Keener',\n",
       " 'Joby of Leie',\n",
       " 'Joby of Zerne',\n",
       " 'Joby of XIII',\n",
       " 'Joby of Cresser',\n",
       " 'Joby of Vecher',\n",
       " 'Joby of Brybblo',\n",
       " 'Joby of Nieq',\n",
       " 'Joby of Mei']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names('Joby of ', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joby the Queen',\n",
       " 'Joby the Worrina',\n",
       " 'Joby the Erondour',\n",
       " 'Joby the Rabe',\n",
       " 'Joby the Tazephien',\n",
       " \"Joby the Ye'nard Ma\",\n",
       " 'Joby the Urage',\n",
       " 'Joby the Iglandsorne',\n",
       " 'Joby the Oakville',\n",
       " 'Joby the Prepesonord',\n",
       " 'Joby the Aleghring',\n",
       " 'Joby the Sepersant',\n",
       " 'Joby the Daraldi',\n",
       " 'Joby the Fabrongo',\n",
       " 'Joby the Grade',\n",
       " 'Joby the Hugeh',\n",
       " 'Joby the Jreane',\n",
       " 'Joby the Korten',\n",
       " 'Joby the Lougis',\n",
       " 'Joby the Zadges',\n",
       " 'Joby the Xokkhail',\n",
       " 'Joby the Chamelka',\n",
       " 'Joby the Vaimignaix',\n",
       " 'Joby the Brinpe',\n",
       " 'Joby the Naighessa',\n",
       " 'Joby the Maske']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names('Joby the ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quata of Quen\n",
      "Quata of Watch\n",
      "Quata of E-Th\n",
      "Quata of Rur Bus\n",
      "Quata of Teema\n",
      "Quata of Yusair\n",
      "Quata of Urmukk\n",
      "Quata of IV\n",
      "Quata of Orumust\n",
      "Quata of Pilmurl\n",
      "Quata of Arlmuttre\n",
      "Quata of Sajudo\n",
      "Quata of Drid Tailam\n",
      "Quata of Fat at She\n",
      "Quata of Gayu\n",
      "Quata of Hasulfram\n",
      "Quata of Jea\n",
      "Quata of Kia\n",
      "Quata of Lumura\n",
      "Quata of Zelch\n",
      "Quata of XVII\n",
      "Quata of Carlumpe\n",
      "Quata of Vather\n",
      "Quata of Bruththin\n",
      "Quata of Neku\n",
      "Quata of Mamuri\n",
      "Wimero of Qeyen\n",
      "Wimero of Waldarro\n",
      "Wimero of Ebenour\n",
      "Wimero of Ra'Ohand\n",
      "Wimero of Tuner\n",
      "Wimero of Yanbackory\n",
      "Wimero of Ulmaldo\n",
      "Wimero of IXIcharias\n",
      "Wimero of Ome\n",
      "Wimero of Pupita\n",
      "Wimero of Aulmbals\n",
      "Wimero of Sabont of\n",
      "Wimero of Delacha\n",
      "Wimero of Fornama\n",
      "Wimero of Gagralo\n",
      "Wimero of Heulbgiclo\n",
      "Wimero of Jeen\n",
      "Wimero of Kirasus\n",
      "Wimero of Lasserkain\n",
      "Wimero of Zarda\n",
      "Wimero of Xanrih\n",
      "Wimero of Camalyon\n",
      "Wimero of VIv Minea\n",
      "Wimero of Bamuda\n",
      "Wimero of Naggosso\n",
      "Wimero of Mishuld\n",
      "Emperan of Queen\n",
      "Emperan of Wernel Celemobyr\n",
      "Emperan of Elsmild\n",
      "Emperan of Rewlur\n",
      "Emperan of Trever\n",
      "Emperan of Yonnu\n",
      "Emperan of Undyriem\n",
      "Emperan of IVicheraim\n",
      "Emperan of Ohberron\n",
      "Emperan of Prenntyte\n",
      "Emperan of Almaso\n",
      "Emperan of Serl\n",
      "Emperan of Dernel\n",
      "Emperan of Frunhart\n",
      "Emperan of Grands\n",
      "Emperan of Haildruse\n",
      "Emperan of Jee\n",
      "Emperan of Keen\n",
      "Emperan of Lishersar Ackeralme\n",
      "Emperan of Zar\n",
      "Emperan of XVirenarte\n",
      "Emperan of Cheviaut Ssentresia\n",
      "Emperan of VIdou\n",
      "Emperan of Bunremus\n",
      "Emperan of Nox\n",
      "Emperan of Messearca\n",
      "Ran of Quinz on de Fabrugumu\n",
      "Ran of Warres\n",
      "Ran of Emmiro\n",
      "Ran of Resm Artharss\n",
      "Ran of Timilo\n",
      "Ran of Yanguh IIginaga\n",
      "Ran of Ullurd\n",
      "Ran of Ironhearts\n",
      "Ran of Ommind\n",
      "Ran of Porgais Garalti\n",
      "Ran of Amburobos\n",
      "Ran of Stoma-Siunk\n",
      "Ran of Diriso\n",
      "Ran of Frond\n",
      "Ran of Gimper\n",
      "Ran of Helle\n",
      "Ran of Jirt\n",
      "Ran of Keggare Cerulamotte\n",
      "Ran of Lucih\n",
      "Ran of Ze Troshor\n",
      "Ran of XIII\n",
      "Ran of Carlen\n",
      "Ran of VIII\n",
      "Ran of Belabarch\n",
      "Ran of Nector\n",
      "Ran of Mine Fophersa\n",
      "Terny of Queet\n",
      "Terny of Waldhtern\n",
      "Terny of Elmtoi\n",
      "Terny of Ruges\n",
      "Terny of Tairm\n",
      "Terny of Ylaur\n",
      "Terny of Ulma\n",
      "Terny of Irmutit\n",
      "Terny of Ordor\n",
      "Terny of Prextess\n",
      "Terny of Aurders\n",
      "Terny of Shot\n",
      "Terny of Dremuso\n",
      "Terny of F'margin\n",
      "Terny of Gurdus\n",
      "Terny of Hyrril\n",
      "Terny of Jerund\n",
      "Terny of Keeple\n",
      "Terny of Liend\n",
      "Terny of Zate\n",
      "Terny of XVII\n",
      "Terny of Cruepst Lelk\n",
      "Terny of Verra\n",
      "Terny of Blacher\n",
      "Terny of Nux\n",
      "Terny of Mato\n",
      "Yoshuran's of Queema-Ta-Zenn\n",
      "Yoshuran's of Warvouler\n",
      "Yoshuran's of Elbhoro\n",
      "Yoshuran's of Ruce\n",
      "Yoshuran's of Tht Lusa\n",
      "Yoshuran's of Yuser\n",
      "Yoshuran's of Ulamein\n",
      "Yoshuran's of IXII\n",
      "Yoshuran's of Owlmurd\n",
      "Yoshuran's of Palmura\n",
      "Yoshuran's of Aummustain\n",
      "Yoshuran's of Sum\n",
      "Yoshuran's of Demica\n",
      "Yoshuran's of Fuecbarce\n",
      "Yoshuran's of Guart\n",
      "Yoshuran's of H\n",
      "Yoshuran's of Juguel\n",
      "Yoshuran's of Koru\n",
      "Yoshuran's of L Quurouk\n",
      "Yoshuran's of Zumic\n",
      "Yoshuran's of XV\n",
      "Yoshuran's of Cueuma\n",
      "Yoshuran's of Va\n",
      "Yoshuran's of Burmbla\n",
      "Yoshuran's of Nuuugo\n",
      "Yoshuran's of Mukuer\n",
      "Uli of Quee\n",
      "Uli of Warra\n",
      "Uli of Elfula\n",
      "Uli of Reintai\n",
      "Uli of Taane\n",
      "Uli of Yather\n",
      "Uli of Ulchmar\n",
      "Uli of I\n",
      "Uli of Oufberr\n",
      "Uli of Pairu\n",
      "Uli of Arona\n",
      "Uli of Systert\n",
      "Uli of Deneit\n",
      "Uli of Francha\n",
      "Uli of Guadre\n",
      "Uli of Harmil\n",
      "Uli of Jave\n",
      "Uli of Kanch\n",
      "Uli of Leff\n",
      "Uli of Zoa\n",
      "Uli of XVI\n",
      "Uli of Carumar\n",
      "Uli of Vilea\n",
      "Uli of Baimbla\n",
      "Uli of Navie\n",
      "Uli of M de\n",
      "Irna of Queen Salmurca\n",
      "Irna of Wramer\n",
      "Irna of Eymer\n",
      "Irna of Resca\n",
      "Irna of Toun\n",
      "Irna of Ya Seire\n",
      "Irna of Untum\n",
      "Irna of Istauler\n",
      "Irna of Orders\n",
      "Irna of Purller Mani\n",
      "Irna of Arinie\n",
      "Irna of Striff\n",
      "Irna of Daimus\n",
      "Irna of Farter\n",
      "Irna of Gurtmain\n",
      "Irna of Herrea\n",
      "Irna of Jerden\n",
      "Irna of Krena\n",
      "Irna of Lick\n",
      "Irna of Zimis\n",
      "Irna of XVI\n",
      "Irna of Caito\n",
      "Irna of Vexer\n",
      "Irna of Brignhin\n",
      "Irna of Nawanay\n",
      "Irna of Madaud\n",
      "Ongalf of Quoun\n",
      "Ongalf of Worme\n",
      "Ongalf of Ernal\n",
      "Ongalf of Ragus\n",
      "Ongalf of Tamini\n",
      "Ongalf of Yo\n",
      "Ongalf of Unalero\n",
      "Ongalf of IV\n",
      "Ongalf of Orbela\n",
      "Ongalf of Prim\n",
      "Ongalf of A de\n",
      "Ongalf of Strmact\n",
      "Ongalf of Dermarge\n",
      "Ongalf of Farlemon\n",
      "Ongalf of Gardo\n",
      "Ongalf of Himika\n",
      "Ongalf of Jernen\n",
      "Ongalf of Kanta\n",
      "Ongalf of Lederran\n",
      "Ongalf of Zad\n",
      "Ongalf of XVI\n",
      "Ongalf of Chriupove\n",
      "Ongalf of Vickbarr\n",
      "Ongalf of Bartomi\n",
      "Ongalf of Nazga\n",
      "Ongalf of Magiea\n",
      "Perian of Queu\n",
      "Perian of Waperrim\n",
      "Perian of Eryti\n",
      "Perian of Ross\n",
      "Perian of Train\n",
      "Perian of Ying\n",
      "Perian of Underd\n",
      "Perian of IVminuti\n",
      "Perian of Oeger\n",
      "Perian of Purus\n",
      "Perian of Armus\n",
      "Perian of Suptef\n",
      "Perian of Deene\n",
      "Perian of Fetrei\n",
      "Perian of Gueull\n",
      "Perian of Heurina\n",
      "Perian of Jyee\n",
      "Perian of Kisaio\n",
      "Perian of Lusiss\n",
      "Perian of Zertt\n",
      "Perian of XVII\n",
      "Perian of Chavertre\n",
      "Perian of Vinelura\n",
      "Perian of Brogus\n",
      "Perian of Nai\n",
      "Perian of Muge\n",
      "Ageni of Queen Selindia\n",
      "Ageni of Warrer\n",
      "Ageni of Eumaggs\n",
      "Ageni of Rasherstrev\n",
      "Ageni of Thmmer\n",
      "Ageni of Yeim\n",
      "Ageni of Ubeles\n",
      "Ageni of IV\n",
      "Ageni of Ornen\n",
      "Ageni of Prinasts\n",
      "Ageni of A dea\n",
      "Ageni of Sierds\n",
      "Ageni of Denarael\n",
      "Ageni of Fiun\n",
      "Ageni of Gaidor\n",
      "Ageni of Hinari\n",
      "Ageni of Jelen\n",
      "Ageni of Kumer\n",
      "Ageni of Lemandra\n",
      "Ageni of Zelgerra\n",
      "Ageni of XII\n",
      "Ageni of Criscens\n",
      "Ageni of Veliural\n",
      "Ageni of Bighti\n",
      "Ageni of Nyle\n",
      "Ageni of Myrule\n",
      "Saraha of Qeen\n",
      "Saraha of Widgr\n",
      "Saraha of Eadvir\n",
      "Saraha of Reephrain Cammusta\n",
      "Saraha of Tran\n",
      "Saraha of Yuhago\n",
      "Saraha of Ul Malvim\n",
      "Saraha of Izokit\n",
      "Saraha of Olfos\n",
      "Saraha of Patrie\n",
      "Saraha of Alumpia\n",
      "Saraha of Shepit\n",
      "Saraha of Dzem\n",
      "Saraha of Frammir\n",
      "Saraha of Guat/Fanry\n",
      "Saraha of Haod\n",
      "Saraha of Juep\n",
      "Saraha of Kango\n",
      "Saraha of Lumuri\n",
      "Saraha of Zerne\n",
      "Saraha of XII\n",
      "Saraha of Cornemi\n",
      "Saraha of Vqyan\n",
      "Saraha of Blutes\n",
      "Saraha of Nestoq\n",
      "Saraha of Magg's\n",
      "Djall of Queen\n",
      "Djall of Wargwers\n",
      "Djall of Elatre\n",
      "Djall of Raset\n",
      "Djall of Trays\n",
      "Djall of Yothast\n",
      "Djall of Untzest\n",
      "Djall of III\n",
      "Djall of Otsermake\n",
      "Djall of Pzasiot\n",
      "Djall of Arothth\n",
      "Djall of Stelma\n",
      "Djall of Dee\n",
      "Djall of Farine\n",
      "Djall of Guck\n",
      "Djall of Honguzi Ole\n",
      "Djall of Jeyk\n",
      "Djall of Krent Serinches\n",
      "Djall of Lector\n",
      "Djall of Zezo\n",
      "Djall of XII\n",
      "Djall of Crempaut\n",
      "Djall of V\n",
      "Djall of Bachersta\n",
      "Djall of Nade\n",
      "Djall of Madi\n",
      "Faya of Quene de Corogagneitsse\n",
      "Faya of Welta\n",
      "Faya of Erighor\n",
      "Faya of Restiel\n",
      "Faya of Teer\n",
      "Faya of Y-Sekka\n",
      "Faya of Ulfhmart\n",
      "Faya of IV\n",
      "Faya of Owgur\n",
      "Faya of Preip Freumerus\n",
      "Faya of Arna\n",
      "Faya of Stlenchan\n",
      "Faya of Deen's Shal Alanata\n",
      "Faya of Frage\n",
      "Faya of Gruma\n",
      "Faya of Hex\n",
      "Faya of Jalges\n",
      "Faya of Keeper\n",
      "Faya of Lene\n",
      "Faya of Zern\n",
      "Faya of XVerruck\n",
      "Faya of Carusumu\n",
      "Faya of Vether\n",
      "Faya of Buddeers\n",
      "Faya of Nenrosn v\n",
      "Faya of Mudeed\n",
      "Galorat of Qeose\n",
      "Galorat of Wrantakyr Faldos\n",
      "Galorat of Ellem\n",
      "Galorat of Rop Fournal\n",
      "Galorat of Tinarame\n",
      "Galorat of Yohsear\n",
      "Galorat of Ulmmurd\n",
      "Galorat of IV\n",
      "Galorat of Oldem\n",
      "Galorat of Partion\n",
      "Galorat of Armemet Buunfiri\n",
      "Galorat of Sueqa\n",
      "Galorat of Daruto\n",
      "Galorat of Flade\n",
      "Galorat of Guyer\n",
      "Galorat of Heurleara\n",
      "Galorat of Joe\n",
      "Galorat of Kano\n",
      "Galorat of Leigeerd\n",
      "Galorat of Zerra\n",
      "Galorat of XIII\n",
      "Galorat of Crisusus\n",
      "Galorat of VIr Tharta\n",
      "Galorat of Banhardina\n",
      "Galorat of Naunesmal\n",
      "Galorat of Mataicae\n",
      "Hayamodre of Queen\n",
      "Hayamodre of Wrido\n",
      "Hayamodre of Eustemp\n",
      "Hayamodre of Rosfiers\n",
      "Hayamodre of Tumot\n",
      "Hayamodre of Yooma\n",
      "Hayamodre of Ulmeon\n",
      "Hayamodre of IV\n",
      "Hayamodre of Older\n",
      "Hayamodre of Pougle\n",
      "Hayamodre of Aumbalmmid Ginn\n",
      "Hayamodre of Smirne\n",
      "Hayamodre of Dedeerd Malddorogg\n",
      "Hayamodre of Fantons io\n",
      "Hayamodre of Gurde\n",
      "Hayamodre of Hauram\n",
      "Hayamodre of Juid\n",
      "Hayamodre of Kunmard\n",
      "Hayamodre of Leiggs\n",
      "Hayamodre of Zenra\n",
      "Hayamodre of XIV\n",
      "Hayamodre of Carnan\n",
      "Hayamodre of Vavelorny\n",
      "Hayamodre of Blohtrond\n",
      "Hayamodre of Nofsor\n",
      "Hayamodre of Minger\n",
      "Jehlah of Queenjur\n",
      "Jehlah of Warsum\n",
      "Jehlah of Eard\n",
      "Jehlah of Rammestra\n",
      "Jehlah of Toratzo\n",
      "Jehlah of Yuras\n",
      "Jehlah of Undaris\n",
      "Jehlah of Iuder\n",
      "Jehlah of Ormanu\n",
      "Jehlah of Parahes\n",
      "Jehlah of Armita\n",
      "Jehlah of Salder\n",
      "Jehlah of Dierd\n",
      "Jehlah of Fauruta\n",
      "Jehlah of Guasomo\n",
      "Jehlah of Heurraugne\n",
      "Jehlah of Jerne\n",
      "Jehlah of Krom\n",
      "Jehlah of Laiesm\n",
      "Jehlah of Zerly\n",
      "Jehlah of Xof Jeant\n",
      "Jehlah of Chankle\n",
      "Jehlah of Vivilis\n",
      "Jehlah of Bard taeTrick\n",
      "Jehlah of Nomaga\n",
      "Jehlah of Mendre\n",
      "Kenn of Queen\n",
      "Kenn of Wyrne\n",
      "Kenn of Elmhtiv\n",
      "Kenn of Rugglof\n",
      "Kenn of Trophery\n",
      "Kenn of Yunges\n",
      "Kenn of Urmphain\n",
      "Kenn of Ir Bugtor\n",
      "Kenn of Orks\n",
      "Kenn of Pirale\n",
      "Kenn of Autur\n",
      "Kenn of Shiputo\n",
      "Kenn of Dainbous\n",
      "Kenn of Flater\n",
      "Kenn of Gylla\n",
      "Kenn of Hungy\n",
      "Kenn of Juks\n",
      "Kenn of Krim\n",
      "Kenn of Luiugis\n",
      "Kenn of Zalmer\n",
      "Kenn of XII\n",
      "Kenn of Cornd\n",
      "Kenn of V\n",
      "Kenn of Broh Almut\n",
      "Kenn of Namimo\n",
      "Kenn of Muhche\n",
      "Leri of Queen\n",
      "Leri of Warren\n",
      "Leri of Estol\n",
      "Leri of Rusler\n",
      "Leri of Trames\n",
      "Leri of Yone\n",
      "Leri of Uldour\n",
      "Leri of Itonia\n",
      "Leri of Oakk\n",
      "Leri of Parmard\n",
      "Leri of Arshors\n",
      "Leri of Selturo\n",
      "Leri of D. Nounes\n",
      "Leri of Faire\n",
      "Leri of Gurva\n",
      "Leri of Hy'qa\n",
      "Leri of Je'na de Than\n",
      "Leri of Kuntess\n",
      "Leri of Luveir\n",
      "Leri of Zevier\n",
      "Leri of XII\n",
      "Leri of Cluit\n",
      "Leri of Valex\n",
      "Leri of Boughta\n",
      "Leri of Nougo\n",
      "Leri of Mangus\n",
      "Zeo-Ruime of Queen\n",
      "Zeo-Ruime of Waltus\n",
      "Zeo-Ruime of Eryne\n",
      "Zeo-Ruime of Rinch\n",
      "Zeo-Ruime of Thef\n",
      "Zeo-Ruime of Yigha\n",
      "Zeo-Ruime of Uldrail\n",
      "Zeo-Ruime of I\n",
      "Zeo-Ruime of Obli\n",
      "Zeo-Ruime of Parrima\n",
      "Zeo-Ruime of Aimibrolt\n",
      "Zeo-Ruime of Smepiria\n",
      "Zeo-Ruime of Damma\n",
      "Zeo-Ruime of Fintr\n",
      "Zeo-Ruime of Guuruh\n",
      "Zeo-Ruime of Hexph\n",
      "Zeo-Ruime of Jihne\n",
      "Zeo-Ruime of Kunis\n",
      "Zeo-Ruime of Lenhal\n",
      "Zeo-Ruime of Zeldaere\n",
      "Zeo-Ruime of XVII\n",
      "Zeo-Ruime of Chird\n",
      "Zeo-Ruime of Vel Aaperiep\n",
      "Zeo-Ruime of Banty\n",
      "Zeo-Ruime of Nougnead\n",
      "Zeo-Ruime of Ma The\n",
      "Xagg of Queen of VII\n",
      "Xagg of Widg\n",
      "Xagg of Eafira\n",
      "Xagg of Radder\n",
      "Xagg of Tilan\n",
      "Xagg of Yorna\n",
      "Xagg of Under\n",
      "Xagg of IXIh Cauluman\n",
      "Xagg of Olberian\n",
      "Xagg of Prumpant\n",
      "Xagg of Asenard\n",
      "Xagg of Sager\n",
      "Xagg of Durna\n",
      "Xagg of Faira\n",
      "Xagg of Gamnard\n",
      "Xagg of Hannerdion\n",
      "Xagg of Jaeque\n",
      "Xagg of Kumeri\n",
      "Xagg of Liett\n",
      "Xagg of Zerder Lenaud\n",
      "Xagg of XVIIV\n",
      "Xagg of Crespara\n",
      "Xagg of Vamathia\n",
      "Xagg of Berd\n",
      "Xagg of N Masherra\n",
      "Xagg of M'naag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cidagolard of Queenne\n",
      "Cidagolard of Wernny\n",
      "Cidagolard of Eelum\n",
      "Cidagolard of Raim Pansa\n",
      "Cidagolard of Tumov\n",
      "Cidagolard of Yaggsss de Bairumas\n",
      "Cidagolard of Ular\n",
      "Cidagolard of IVdiccanar\n",
      "Cidagolard of Orbolph\n",
      "Cidagolard of Prouges\n",
      "Cidagolard of Allumo\n",
      "Cidagolard of Sellurd\n",
      "Cidagolard of Dalmacion\n",
      "Cidagolard of Futrigean\n",
      "Cidagolard of Guond\n",
      "Cidagolard of Hilgasi\n",
      "Cidagolard of Juges\n",
      "Cidagolard of Kubor\n",
      "Cidagolard of Lugglair\n",
      "Cidagolard of Zuburns\n",
      "Cidagolard of XII\n",
      "Cidagolard of Cresant XVII\n",
      "Cidagolard of V\n",
      "Cidagolard of Bullugin\n",
      "Cidagolard of Naugea\n",
      "Cidagolard of Mangesgers\n",
      "Viloteen of Queen\n",
      "Viloteen of Wirne\n",
      "Viloteen of Elstullv\n",
      "Viloteen of Re Hana\n",
      "Viloteen of Tleura\n",
      "Viloteen of Youits\n",
      "Viloteen of Ulmari\n",
      "Viloteen of IV\n",
      "Viloteen of Ool\n",
      "Viloteen of Puntestaix\n",
      "Viloteen of Allearvine\n",
      "Viloteen of Sartas\n",
      "Viloteen of Daine\n",
      "Viloteen of Fenbarce\n",
      "Viloteen of Grove\n",
      "Viloteen of Hotrea\n",
      "Viloteen of Jiens\n",
      "Viloteen of Kant\n",
      "Viloteen of Lucure\n",
      "Viloteen of Zeedare Fe\n",
      "Viloteen of XIV\n",
      "Viloteen of Cidiansss\n",
      "Viloteen of Vestra\n",
      "Viloteen of Blied\n",
      "Viloteen of Naukaria\n",
      "Viloteen of Manteria\n",
      "Bahton of Queen\n",
      "Bahton of Walth\n",
      "Bahton of Elmard\n",
      "Bahton of Rosferland\n",
      "Bahton of Then of VIrcarra\n",
      "Bahton of Yompmand\n",
      "Bahton of Urch\n",
      "Bahton of Irdiagh\n",
      "Bahton of Ord\n",
      "Bahton of Pucror\n",
      "Bahton of Alghair\n",
      "Bahton of Sandaranch\n",
      "Bahton of Danet\n",
      "Bahton of Fornea\n",
      "Bahton of Go\n",
      "Bahton of Hadgeser\n",
      "Bahton of Jandos\n",
      "Bahton of Kiggger\n",
      "Bahton of Luku\n",
      "Bahton of Zearo\n",
      "Bahton of XXII\n",
      "Bahton of Cangus\n",
      "Bahton of Valeroale\n",
      "Bahton of Bonnein\n",
      "Bahton of Noxga\n",
      "Bahton of Magheron\n",
      "Noro of Quoun Guspe\n",
      "Noro of Waugum\n",
      "Noro of Ember\n",
      "Noro of Rot\n",
      "Noro of Trengaha\n",
      "Noro of Yonders\n",
      "Noro of Unchnca\n",
      "Noro of Ire\n",
      "Noro of Okkur\n",
      "Noro of Phinata\n",
      "Noro of A-Sadnah\n",
      "Noro of Suembris\n",
      "Noro of Dalvas\n",
      "Noro of Floh\n",
      "Noro of Gudgo\n",
      "Noro of Hynela\n",
      "Noro of Jaeb\n",
      "Noro of Kurum\n",
      "Noro of Lonnesch\n",
      "Noro of Zewge\n",
      "Noro of XV\n",
      "Noro of Chuppoin\n",
      "Noro of Valauura\n",
      "Noro of Burdler\n",
      "Noro of Nerrall\n",
      "Noro of Mibulb\n",
      "Madehteria of Queen\n",
      "Madehteria of Wigit\n",
      "Madehteria of Eldiers\n",
      "Madehteria of Ryifes\n",
      "Madehteria of Treepetr\n",
      "Madehteria of Yurdrich\n",
      "Madehteria of Urmera\n",
      "Madehteria of IIgoral\n",
      "Madehteria of Ordders\n",
      "Madehteria of Prisamusce\n",
      "Madehteria of Aldorn\n",
      "Madehteria of Supure\n",
      "Madehteria of Deestaix\n",
      "Madehteria of Fummelmu\n",
      "Madehteria of Gueldros\n",
      "Madehteria of Herglaine\n",
      "Madehteria of Jueene\n",
      "Madehteria of Kerne\n",
      "Madehteria of Luires\n",
      "Madehteria of Zerd\n",
      "Madehteria of XII\n",
      "Madehteria of Creaplish\n",
      "Madehteria of VIIcheracain\n",
      "Madehteria of Balesta\n",
      "Madehteria of Noupern\n",
      "Madehteria of Moddes\n"
     ]
    }
   ],
   "source": [
    "place = []\n",
    "for name in generate_names():\n",
    "    name = name.split()[0]\n",
    "    for long_name in generate_names(name + \" of \"):\n",
    "        print(long_name)\n",
    "        place.append(long_name.split()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quen',\n",
       " 'Watch',\n",
       " 'E-Th',\n",
       " 'Rur',\n",
       " 'Teema',\n",
       " 'Yusair',\n",
       " 'Urmukk',\n",
       " 'IV',\n",
       " 'Orumust',\n",
       " 'Pilmurl',\n",
       " 'Arlmuttre',\n",
       " 'Sajudo',\n",
       " 'Drid',\n",
       " 'Fat',\n",
       " 'Gayu',\n",
       " 'Hasulfram',\n",
       " 'Jea',\n",
       " 'Kia',\n",
       " 'Lumura',\n",
       " 'Zelch',\n",
       " 'XVII',\n",
       " 'Carlumpe',\n",
       " 'Vather',\n",
       " 'Bruththin',\n",
       " 'Neku',\n",
       " 'Mamuri',\n",
       " 'Qeyen',\n",
       " 'Waldarro',\n",
       " 'Ebenour',\n",
       " \"Ra'Ohand\",\n",
       " 'Tuner',\n",
       " 'Yanbackory',\n",
       " 'Ulmaldo',\n",
       " 'IXIcharias',\n",
       " 'Ome',\n",
       " 'Pupita',\n",
       " 'Aulmbals',\n",
       " 'Sabont',\n",
       " 'Delacha',\n",
       " 'Fornama',\n",
       " 'Gagralo',\n",
       " 'Heulbgiclo',\n",
       " 'Jeen',\n",
       " 'Kirasus',\n",
       " 'Lasserkain',\n",
       " 'Zarda',\n",
       " 'Xanrih',\n",
       " 'Camalyon',\n",
       " 'VIv',\n",
       " 'Bamuda',\n",
       " 'Naggosso',\n",
       " 'Mishuld',\n",
       " 'Queen',\n",
       " 'Wernel',\n",
       " 'Elsmild',\n",
       " 'Rewlur',\n",
       " 'Trever',\n",
       " 'Yonnu',\n",
       " 'Undyriem',\n",
       " 'IVicheraim',\n",
       " 'Ohberron',\n",
       " 'Prenntyte',\n",
       " 'Almaso',\n",
       " 'Serl',\n",
       " 'Dernel',\n",
       " 'Frunhart',\n",
       " 'Grands',\n",
       " 'Haildruse',\n",
       " 'Jee',\n",
       " 'Keen',\n",
       " 'Lishersar',\n",
       " 'Zar',\n",
       " 'XVirenarte',\n",
       " 'Cheviaut',\n",
       " 'VIdou',\n",
       " 'Bunremus',\n",
       " 'Nox',\n",
       " 'Messearca',\n",
       " 'Quinz',\n",
       " 'Warres',\n",
       " 'Emmiro',\n",
       " 'Resm',\n",
       " 'Timilo',\n",
       " 'Yanguh',\n",
       " 'Ullurd',\n",
       " 'Ironhearts',\n",
       " 'Ommind',\n",
       " 'Porgais',\n",
       " 'Amburobos',\n",
       " 'Stoma-Siunk',\n",
       " 'Diriso',\n",
       " 'Frond',\n",
       " 'Gimper',\n",
       " 'Helle',\n",
       " 'Jirt',\n",
       " 'Keggare',\n",
       " 'Lucih',\n",
       " 'Ze',\n",
       " 'XIII',\n",
       " 'Carlen',\n",
       " 'VIII',\n",
       " 'Belabarch',\n",
       " 'Nector',\n",
       " 'Mine',\n",
       " 'Queet',\n",
       " 'Waldhtern',\n",
       " 'Elmtoi',\n",
       " 'Ruges',\n",
       " 'Tairm',\n",
       " 'Ylaur',\n",
       " 'Ulma',\n",
       " 'Irmutit',\n",
       " 'Ordor',\n",
       " 'Prextess',\n",
       " 'Aurders',\n",
       " 'Shot',\n",
       " 'Dremuso',\n",
       " \"F'margin\",\n",
       " 'Gurdus',\n",
       " 'Hyrril',\n",
       " 'Jerund',\n",
       " 'Keeple',\n",
       " 'Liend',\n",
       " 'Zate',\n",
       " 'XVII',\n",
       " 'Cruepst',\n",
       " 'Verra',\n",
       " 'Blacher',\n",
       " 'Nux',\n",
       " 'Mato',\n",
       " 'Queema-Ta-Zenn',\n",
       " 'Warvouler',\n",
       " 'Elbhoro',\n",
       " 'Ruce',\n",
       " 'Tht',\n",
       " 'Yuser',\n",
       " 'Ulamein',\n",
       " 'IXII',\n",
       " 'Owlmurd',\n",
       " 'Palmura',\n",
       " 'Aummustain',\n",
       " 'Sum',\n",
       " 'Demica',\n",
       " 'Fuecbarce',\n",
       " 'Guart',\n",
       " 'H',\n",
       " 'Juguel',\n",
       " 'Koru',\n",
       " 'L',\n",
       " 'Zumic',\n",
       " 'XV',\n",
       " 'Cueuma',\n",
       " 'Va',\n",
       " 'Burmbla',\n",
       " 'Nuuugo',\n",
       " 'Mukuer',\n",
       " 'Quee',\n",
       " 'Warra',\n",
       " 'Elfula',\n",
       " 'Reintai',\n",
       " 'Taane',\n",
       " 'Yather',\n",
       " 'Ulchmar',\n",
       " 'I',\n",
       " 'Oufberr',\n",
       " 'Pairu',\n",
       " 'Arona',\n",
       " 'Systert',\n",
       " 'Deneit',\n",
       " 'Francha',\n",
       " 'Guadre',\n",
       " 'Harmil',\n",
       " 'Jave',\n",
       " 'Kanch',\n",
       " 'Leff',\n",
       " 'Zoa',\n",
       " 'XVI',\n",
       " 'Carumar',\n",
       " 'Vilea',\n",
       " 'Baimbla',\n",
       " 'Navie',\n",
       " 'M',\n",
       " 'Queen',\n",
       " 'Wramer',\n",
       " 'Eymer',\n",
       " 'Resca',\n",
       " 'Toun',\n",
       " 'Ya',\n",
       " 'Untum',\n",
       " 'Istauler',\n",
       " 'Orders',\n",
       " 'Purller',\n",
       " 'Arinie',\n",
       " 'Striff',\n",
       " 'Daimus',\n",
       " 'Farter',\n",
       " 'Gurtmain',\n",
       " 'Herrea',\n",
       " 'Jerden',\n",
       " 'Krena',\n",
       " 'Lick',\n",
       " 'Zimis',\n",
       " 'XVI',\n",
       " 'Caito',\n",
       " 'Vexer',\n",
       " 'Brignhin',\n",
       " 'Nawanay',\n",
       " 'Madaud',\n",
       " 'Quoun',\n",
       " 'Worme',\n",
       " 'Ernal',\n",
       " 'Ragus',\n",
       " 'Tamini',\n",
       " 'Yo',\n",
       " 'Unalero',\n",
       " 'IV',\n",
       " 'Orbela',\n",
       " 'Prim',\n",
       " 'A',\n",
       " 'Strmact',\n",
       " 'Dermarge',\n",
       " 'Farlemon',\n",
       " 'Gardo',\n",
       " 'Himika',\n",
       " 'Jernen',\n",
       " 'Kanta',\n",
       " 'Lederran',\n",
       " 'Zad',\n",
       " 'XVI',\n",
       " 'Chriupove',\n",
       " 'Vickbarr',\n",
       " 'Bartomi',\n",
       " 'Nazga',\n",
       " 'Magiea',\n",
       " 'Queu',\n",
       " 'Waperrim',\n",
       " 'Eryti',\n",
       " 'Ross',\n",
       " 'Train',\n",
       " 'Ying',\n",
       " 'Underd',\n",
       " 'IVminuti',\n",
       " 'Oeger',\n",
       " 'Purus',\n",
       " 'Armus',\n",
       " 'Suptef',\n",
       " 'Deene',\n",
       " 'Fetrei',\n",
       " 'Gueull',\n",
       " 'Heurina',\n",
       " 'Jyee',\n",
       " 'Kisaio',\n",
       " 'Lusiss',\n",
       " 'Zertt',\n",
       " 'XVII',\n",
       " 'Chavertre',\n",
       " 'Vinelura',\n",
       " 'Brogus',\n",
       " 'Nai',\n",
       " 'Muge',\n",
       " 'Queen',\n",
       " 'Warrer',\n",
       " 'Eumaggs',\n",
       " 'Rasherstrev',\n",
       " 'Thmmer',\n",
       " 'Yeim',\n",
       " 'Ubeles',\n",
       " 'IV',\n",
       " 'Ornen',\n",
       " 'Prinasts',\n",
       " 'A',\n",
       " 'Sierds',\n",
       " 'Denarael',\n",
       " 'Fiun',\n",
       " 'Gaidor',\n",
       " 'Hinari',\n",
       " 'Jelen',\n",
       " 'Kumer',\n",
       " 'Lemandra',\n",
       " 'Zelgerra',\n",
       " 'XII',\n",
       " 'Criscens',\n",
       " 'Veliural',\n",
       " 'Bighti',\n",
       " 'Nyle',\n",
       " 'Myrule',\n",
       " 'Qeen',\n",
       " 'Widgr',\n",
       " 'Eadvir',\n",
       " 'Reephrain',\n",
       " 'Tran',\n",
       " 'Yuhago',\n",
       " 'Ul',\n",
       " 'Izokit',\n",
       " 'Olfos',\n",
       " 'Patrie',\n",
       " 'Alumpia',\n",
       " 'Shepit',\n",
       " 'Dzem',\n",
       " 'Frammir',\n",
       " 'Guat/Fanry',\n",
       " 'Haod',\n",
       " 'Juep',\n",
       " 'Kango',\n",
       " 'Lumuri',\n",
       " 'Zerne',\n",
       " 'XII',\n",
       " 'Cornemi',\n",
       " 'Vqyan',\n",
       " 'Blutes',\n",
       " 'Nestoq',\n",
       " \"Magg's\",\n",
       " 'Queen',\n",
       " 'Wargwers',\n",
       " 'Elatre',\n",
       " 'Raset',\n",
       " 'Trays',\n",
       " 'Yothast',\n",
       " 'Untzest',\n",
       " 'III',\n",
       " 'Otsermake',\n",
       " 'Pzasiot',\n",
       " 'Arothth',\n",
       " 'Stelma',\n",
       " 'Dee',\n",
       " 'Farine',\n",
       " 'Guck',\n",
       " 'Honguzi',\n",
       " 'Jeyk',\n",
       " 'Krent',\n",
       " 'Lector',\n",
       " 'Zezo',\n",
       " 'XII',\n",
       " 'Crempaut',\n",
       " 'V',\n",
       " 'Bachersta',\n",
       " 'Nade',\n",
       " 'Madi',\n",
       " 'Quene',\n",
       " 'Welta',\n",
       " 'Erighor',\n",
       " 'Restiel',\n",
       " 'Teer',\n",
       " 'Y-Sekka',\n",
       " 'Ulfhmart',\n",
       " 'IV',\n",
       " 'Owgur',\n",
       " 'Preip',\n",
       " 'Arna',\n",
       " 'Stlenchan',\n",
       " \"Deen's\",\n",
       " 'Frage',\n",
       " 'Gruma',\n",
       " 'Hex',\n",
       " 'Jalges',\n",
       " 'Keeper',\n",
       " 'Lene',\n",
       " 'Zern',\n",
       " 'XVerruck',\n",
       " 'Carusumu',\n",
       " 'Vether',\n",
       " 'Buddeers',\n",
       " 'Nenrosn',\n",
       " 'Mudeed',\n",
       " 'Qeose',\n",
       " 'Wrantakyr',\n",
       " 'Ellem',\n",
       " 'Rop',\n",
       " 'Tinarame',\n",
       " 'Yohsear',\n",
       " 'Ulmmurd',\n",
       " 'IV',\n",
       " 'Oldem',\n",
       " 'Partion',\n",
       " 'Armemet',\n",
       " 'Sueqa',\n",
       " 'Daruto',\n",
       " 'Flade',\n",
       " 'Guyer',\n",
       " 'Heurleara',\n",
       " 'Joe',\n",
       " 'Kano',\n",
       " 'Leigeerd',\n",
       " 'Zerra',\n",
       " 'XIII',\n",
       " 'Crisusus',\n",
       " 'VIr',\n",
       " 'Banhardina',\n",
       " 'Naunesmal',\n",
       " 'Mataicae',\n",
       " 'Queen',\n",
       " 'Wrido',\n",
       " 'Eustemp',\n",
       " 'Rosfiers',\n",
       " 'Tumot',\n",
       " 'Yooma',\n",
       " 'Ulmeon',\n",
       " 'IV',\n",
       " 'Older',\n",
       " 'Pougle',\n",
       " 'Aumbalmmid',\n",
       " 'Smirne',\n",
       " 'Dedeerd',\n",
       " 'Fantons',\n",
       " 'Gurde',\n",
       " 'Hauram',\n",
       " 'Juid',\n",
       " 'Kunmard',\n",
       " 'Leiggs',\n",
       " 'Zenra',\n",
       " 'XIV',\n",
       " 'Carnan',\n",
       " 'Vavelorny',\n",
       " 'Blohtrond',\n",
       " 'Nofsor',\n",
       " 'Minger',\n",
       " 'Queenjur',\n",
       " 'Warsum',\n",
       " 'Eard',\n",
       " 'Rammestra',\n",
       " 'Toratzo',\n",
       " 'Yuras',\n",
       " 'Undaris',\n",
       " 'Iuder',\n",
       " 'Ormanu',\n",
       " 'Parahes',\n",
       " 'Armita',\n",
       " 'Salder',\n",
       " 'Dierd',\n",
       " 'Fauruta',\n",
       " 'Guasomo',\n",
       " 'Heurraugne',\n",
       " 'Jerne',\n",
       " 'Krom',\n",
       " 'Laiesm',\n",
       " 'Zerly',\n",
       " 'Xof',\n",
       " 'Chankle',\n",
       " 'Vivilis',\n",
       " 'Bard',\n",
       " 'Nomaga',\n",
       " 'Mendre',\n",
       " 'Queen',\n",
       " 'Wyrne',\n",
       " 'Elmhtiv',\n",
       " 'Rugglof',\n",
       " 'Trophery',\n",
       " 'Yunges',\n",
       " 'Urmphain',\n",
       " 'Ir',\n",
       " 'Orks',\n",
       " 'Pirale',\n",
       " 'Autur',\n",
       " 'Shiputo',\n",
       " 'Dainbous',\n",
       " 'Flater',\n",
       " 'Gylla',\n",
       " 'Hungy',\n",
       " 'Juks',\n",
       " 'Krim',\n",
       " 'Luiugis',\n",
       " 'Zalmer',\n",
       " 'XII',\n",
       " 'Cornd',\n",
       " 'V',\n",
       " 'Broh',\n",
       " 'Namimo',\n",
       " 'Muhche',\n",
       " 'Queen',\n",
       " 'Warren',\n",
       " 'Estol',\n",
       " 'Rusler',\n",
       " 'Trames',\n",
       " 'Yone',\n",
       " 'Uldour',\n",
       " 'Itonia',\n",
       " 'Oakk',\n",
       " 'Parmard',\n",
       " 'Arshors',\n",
       " 'Selturo',\n",
       " 'D.',\n",
       " 'Faire',\n",
       " 'Gurva',\n",
       " \"Hy'qa\",\n",
       " \"Je'na\",\n",
       " 'Kuntess',\n",
       " 'Luveir',\n",
       " 'Zevier',\n",
       " 'XII',\n",
       " 'Cluit',\n",
       " 'Valex',\n",
       " 'Boughta',\n",
       " 'Nougo',\n",
       " 'Mangus',\n",
       " 'Queen',\n",
       " 'Waltus',\n",
       " 'Eryne',\n",
       " 'Rinch',\n",
       " 'Thef',\n",
       " 'Yigha',\n",
       " 'Uldrail',\n",
       " 'I',\n",
       " 'Obli',\n",
       " 'Parrima',\n",
       " 'Aimibrolt',\n",
       " 'Smepiria',\n",
       " 'Damma',\n",
       " 'Fintr',\n",
       " 'Guuruh',\n",
       " 'Hexph',\n",
       " 'Jihne',\n",
       " 'Kunis',\n",
       " 'Lenhal',\n",
       " 'Zeldaere',\n",
       " 'XVII',\n",
       " 'Chird',\n",
       " 'Vel',\n",
       " 'Banty',\n",
       " 'Nougnead',\n",
       " 'Ma',\n",
       " 'Queen',\n",
       " 'Widg',\n",
       " 'Eafira',\n",
       " 'Radder',\n",
       " 'Tilan',\n",
       " 'Yorna',\n",
       " 'Under',\n",
       " 'IXIh',\n",
       " 'Olberian',\n",
       " 'Prumpant',\n",
       " 'Asenard',\n",
       " 'Sager',\n",
       " 'Durna',\n",
       " 'Faira',\n",
       " 'Gamnard',\n",
       " 'Hannerdion',\n",
       " 'Jaeque',\n",
       " 'Kumeri',\n",
       " 'Liett',\n",
       " 'Zerder',\n",
       " 'XVIIV',\n",
       " 'Crespara',\n",
       " 'Vamathia',\n",
       " 'Berd',\n",
       " 'N',\n",
       " \"M'naag\",\n",
       " 'Queenne',\n",
       " 'Wernny',\n",
       " 'Eelum',\n",
       " 'Raim',\n",
       " 'Tumov',\n",
       " 'Yaggsss',\n",
       " 'Ular',\n",
       " 'IVdiccanar',\n",
       " 'Orbolph',\n",
       " 'Prouges',\n",
       " 'Allumo',\n",
       " 'Sellurd',\n",
       " 'Dalmacion',\n",
       " 'Futrigean',\n",
       " 'Guond',\n",
       " 'Hilgasi',\n",
       " 'Juges',\n",
       " 'Kubor',\n",
       " 'Lugglair',\n",
       " 'Zuburns',\n",
       " 'XII',\n",
       " 'Cresant',\n",
       " 'V',\n",
       " 'Bullugin',\n",
       " 'Naugea',\n",
       " 'Mangesgers',\n",
       " 'Queen',\n",
       " 'Wirne',\n",
       " 'Elstullv',\n",
       " 'Re',\n",
       " 'Tleura',\n",
       " 'Youits',\n",
       " 'Ulmari',\n",
       " 'IV',\n",
       " 'Ool',\n",
       " 'Puntestaix',\n",
       " 'Allearvine',\n",
       " 'Sartas',\n",
       " 'Daine',\n",
       " 'Fenbarce',\n",
       " 'Grove',\n",
       " 'Hotrea',\n",
       " 'Jiens',\n",
       " 'Kant',\n",
       " 'Lucure',\n",
       " 'Zeedare',\n",
       " 'XIV',\n",
       " 'Cidiansss',\n",
       " 'Vestra',\n",
       " 'Blied',\n",
       " 'Naukaria',\n",
       " 'Manteria',\n",
       " 'Queen',\n",
       " 'Walth',\n",
       " 'Elmard',\n",
       " 'Rosferland',\n",
       " 'Then',\n",
       " 'Yompmand',\n",
       " 'Urch',\n",
       " 'Irdiagh',\n",
       " 'Ord',\n",
       " 'Pucror',\n",
       " 'Alghair',\n",
       " 'Sandaranch',\n",
       " 'Danet',\n",
       " 'Fornea',\n",
       " 'Go',\n",
       " 'Hadgeser',\n",
       " 'Jandos',\n",
       " 'Kiggger',\n",
       " 'Luku',\n",
       " 'Zearo',\n",
       " 'XXII',\n",
       " 'Cangus',\n",
       " 'Valeroale',\n",
       " 'Bonnein',\n",
       " 'Noxga',\n",
       " 'Magheron',\n",
       " 'Quoun',\n",
       " 'Waugum',\n",
       " 'Ember',\n",
       " 'Rot',\n",
       " 'Trengaha',\n",
       " 'Yonders',\n",
       " 'Unchnca',\n",
       " 'Ire',\n",
       " 'Okkur',\n",
       " 'Phinata',\n",
       " 'A-Sadnah',\n",
       " 'Suembris',\n",
       " 'Dalvas',\n",
       " 'Floh',\n",
       " 'Gudgo',\n",
       " 'Hynela',\n",
       " 'Jaeb',\n",
       " 'Kurum',\n",
       " 'Lonnesch',\n",
       " 'Zewge',\n",
       " 'XV',\n",
       " 'Chuppoin',\n",
       " 'Valauura',\n",
       " 'Burdler',\n",
       " 'Nerrall',\n",
       " 'Mibulb',\n",
       " 'Queen',\n",
       " 'Wigit',\n",
       " 'Eldiers',\n",
       " 'Ryifes',\n",
       " 'Treepetr',\n",
       " 'Yurdrich',\n",
       " 'Urmera',\n",
       " 'IIgoral',\n",
       " 'Ordders',\n",
       " 'Prisamusce',\n",
       " 'Aldorn',\n",
       " 'Supure',\n",
       " 'Deestaix',\n",
       " 'Fummelmu',\n",
       " 'Gueldros',\n",
       " 'Herglaine',\n",
       " 'Jueene',\n",
       " 'Kerne',\n",
       " 'Luires',\n",
       " 'Zerd',\n",
       " 'XII',\n",
       " 'Creaplish',\n",
       " 'VIIcheracain',\n",
       " 'Balesta',\n",
       " 'Noupern',\n",
       " 'Moddes']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gagralo',\n",
       " 'Gaidor',\n",
       " 'Gamnard',\n",
       " 'Gardo',\n",
       " 'Gayu',\n",
       " 'Gimper',\n",
       " 'Go',\n",
       " 'Grands',\n",
       " 'Grove',\n",
       " 'Gruma',\n",
       " 'Guadre',\n",
       " 'Guart',\n",
       " 'Guasomo',\n",
       " 'Guat/Fanry',\n",
       " 'Guck',\n",
       " 'Gudgo',\n",
       " 'Gueldros',\n",
       " 'Gueull',\n",
       " 'Guond',\n",
       " 'Gurde',\n",
       " 'Gurdus',\n",
       " 'Gurtmain',\n",
       " 'Gurva',\n",
       " 'Guuruh',\n",
       " 'Guyer',\n",
       " 'Gylla']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = list(filter(lambda name: name[0] == \"G\", place))\n",
    "G.sort()\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Verra', 'Bonnein', 'Zertt', 'Prumpant', 'Ulmmurd', 'Preip',\n",
       "       'Ordor', 'Luveir', 'Jeen', 'Jerne'], dtype='<U14')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(place, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Laiesm', 'Iuder', 'Zern', 'Bartomi', 'Striff', 'Izokit', 'Zezo',\n",
       "       'Tleura', 'Sager', 'Ya'], dtype='<U14')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(place, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Older', 'Zerne', 'Teer', 'Burdler', 'Wramer', 'Nyle', 'Raset',\n",
       "       'Sartas', 'IV', 'Kubor'], dtype='<U14')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(place, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quina Tros',\n",
       " 'Widra',\n",
       " \"Edva'virannar\",\n",
       " 'Rapher',\n",
       " 'Thorl',\n",
       " 'Yutah',\n",
       " 'Ulmitothare',\n",
       " 'Indgiel',\n",
       " 'Oe',\n",
       " 'Pitisa',\n",
       " 'Amph',\n",
       " 'Scarice',\n",
       " 'Dr.Sphrader',\n",
       " 'F. Chonnshon',\n",
       " 'Gleaddring',\n",
       " 'Hancel',\n",
       " 'Jell Andoribloy',\n",
       " 'Kurel Aphuralt',\n",
       " 'Lunel',\n",
       " 'Zelika',\n",
       " 'Xermaur',\n",
       " 'Chulor',\n",
       " 'Vaiora',\n",
       " 'Begra Aswerganch',\n",
       " 'Naki',\n",
       " 'Maitha']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
